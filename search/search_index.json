{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#wis2-in-a-box-training","title":"WIS2 in a box training","text":"<p>WIS2 in a box (wis2box) is a Free and Open Source (FOSS) Reference Implementation of a WMO WIS2 Node. The project provides a plug and play toolset to ingest, process, and publish weather/climate/water data using standards-based approaches in alignment with the WIS2 principles. wis2box also provides access to all data in the WIS2 network. wis2box is designed to have a low barrier to entry for data providers, providing enabling infrastructure and services for data discovery, access, and visualization.</p> <p>This training provides step-by-step explanations of various aspects of the wis2box project as well as a number of exercises to help you publish and download data from WIS2.  The training is provided in the form of overview presentations as well as hands-on practical exercises.</p> <p>Participants will be able to work with sample test data and metadata, as well as integrate their own data and metadata.</p> <p>This training covers a wide range of topics (install/setup/configuration, publishing/downloading data, etc.). </p>"},{"location":"#goals-and-learning-outcomes","title":"Goals and learning outcomes","text":"<p>The goals of this training are to become familiar with the following:</p> <ul> <li>WIS2 architecture core concepts and components</li> <li>data and metadata formats used in WIS2 for discovery and access</li> <li>wis2box architecture and environment</li> <li>wis2box core functions:<ul> <li>metadata management</li> <li>data ingest and transformation to BUFR format</li> <li>MQTT broker for WIS2 message publishing</li> <li>HTTP endpoint for data download</li> <li>API endpoint for programmatic access to data</li> </ul> </li> </ul>"},{"location":"#navigation","title":"Navigation","text":"<p>The left hand navigation provides a table of contents for the entire training.</p> <p>The right hand navigation provides a table of contents for a specific page.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":""},{"location":"#knowledge","title":"Knowledge","text":"<ul> <li>Basic Linux commands (see the cheatsheet)</li> <li>Basic knowledge of networking and Internet protocols</li> </ul>"},{"location":"#software","title":"Software","text":"<p>This training requires the following tools:</p> <ul> <li>An instance running Ubuntu OS (provided by WMO trainers during local training sessions) see Accessing your student VM</li> <li>SSH client to access your instance</li> <li>MQTT Explorer on your local machine</li> <li>SCP and FTP client to copy files from your local machine</li> </ul>"},{"location":"#conventions","title":"Conventions","text":"<p>Question</p> <p>A section marked like this invites you to answer a question.</p> <p>Also you will notice tips and notes sections within the text:</p> <p>Tip</p> <p>Tips share help on how to best achieve tasks.</p> <p>Note</p> <p>Notes provide additional information on the topic covered by the practical session, as well as how to best achieve tasks.</p> <p>Examples are indicated as follows:</p> <p>Configuration <pre><code>my-collection-defined-in-yaml:\ntype: collection\ntitle: my title defined as a yaml attribute named title\ndescription: my description as a yaml attribute named description\n</code></pre></p> <p>Snippets which need to be typed in a on a terminal/console are indicated as:</p> <pre><code>echo 'Hello world'\n</code></pre>"},{"location":"#training-location-and-materials","title":"Training location and materials","text":"<p>This training is always provided live at https://training.wis2box.wis.wmo.int.</p> <p>The training contents, wiki and issue tracker are managed on GitHub at https://github.com/wmo-im/wis2box-training.</p>"},{"location":"#printing-the-material","title":"Printing the material","text":"<p>This training can be exported to PDF.  To save or print this training material, go to the print page, and select File &gt; Print &gt; Save as PDF.</p>"},{"location":"#exercise-materials","title":"Exercise materials","text":"<p>Exercise materials can be downloaded from the exercise-materials.zip zipfile.</p>"},{"location":"#support","title":"Support","text":"<p>For issues/bugs/suggestions or improvements/contributions to this training, please use the GitHub issue tracker.</p> <p>All wis2box bugs, enhancements and issues can be reported on GitHub.</p> <p>For additional support of questions, please contact wis@wmo.int.</p> <p>As always, wis2box core documentation can always be found at https://docs.wis2box.wis.wmo.int.</p> <p>Contributions are always encouraged and welcome!</p>"},{"location":"answers/csv2bufr-answers/","title":"Converting CSV data to BUFR answers","text":""},{"location":"answers/csv2bufr-answers/#exercise-1","title":"Exercise 1","text":"<ol> <li>There are 4 header rows.</li> <li>Row 2 contains the column names.</li> <li>Found by checking the lines 6 and 7 in the mapping file.</li> <li>These are found in the <code>data:</code> lines of the mapping file.</li> <li>The CSV data is converted to BUFR using the following command:     <pre><code>csv2bufr data transform ex_1.csv --bufr-template mappings_1.json\n</code></pre></li> <li>The latitude and longitude can be verified using the following command:     <pre><code>bufr_dump -p WIGOS_0-454-2-AWSMULANJE_20230526T005500.bufr4 | egrep -i 'latitude|longitude'\n</code></pre></li> </ol>"},{"location":"answers/csv2bufr-answers/#exercise-2","title":"Exercise 2","text":"<ol> <li> <p>In the previous CSV file, the datetime was split into six columns representing the year, month, day, hour, minute, and second of the observation. In this CSV file, the datetime is stored in a single column.</p> </li> <li> <p>This is done by recreating the six columns of the previous CSV file, and deleting the new datetime column.</p> </li> <li> <p>The CSV data is written to BUFR using:     <pre><code>csv2bufr data transform ex_2.csv --bufr-template mappings_2.json\n</code></pre></p> </li> </ol>"},{"location":"answers/csv2bufr-answers/#exercise-3","title":"Exercise 3","text":"<ol> <li> <p>When running:     <pre><code>csv2bufr data transform ex_3.csv --bufr-template mappings_3.json\n</code></pre></p> <p>You should see the following error:</p> <pre><code>Column RH not found in input data\n</code></pre> <p>followed by the input data dictionary.</p> </li> <li> <p>The relative humidity column now has name <code>RelativeHumidity</code> instead of <code>RH</code>.</p> </li> <li> <p>We do this by changing the line:</p> <pre><code>{\"eccodes_key\": \"#1#relativeHumidity\", \"value\":\"data:RH\"}\n</code></pre> <p>to:</p> <pre><code>{\"eccodes_key\": \"#1#relativeHumidity\", \"value\":\"data:RelativeHumidity\"}\n</code></pre> </li> <li> <p>The CSV data is written to BUFR by re-using:</p> <pre><code>csv2bufr data transform ex_3.csv --bufr-template mappings_3.json\n</code></pre> </li> <li> <p>The relative humidity can be verified using:</p> <pre><code>bufr_dump -p WIGOS_0-454-2-AWSMULANJE_20230526T005500.bufr4 | egrep -i relativeHumidity\n</code></pre> <p>which should give a value of <code>54</code>.</p> <p>Note</p> <p>The value returned is not the same exact value as what is present in the CSV file: 54.09. This is because some variables (such as relative humidity) in BUFR are always integers, hence are rounded.</p> </li> </ol>"},{"location":"answers/csv2bufr-answers/#exercise-4","title":"Exercise 4","text":"<ol> <li>The units are found in row 3.</li> <li>2, as 1hPa = 100Pa.</li> <li>273.15, as 0 degrees C = 273.15 K</li> <li> <p>You should have the following line in your mapppings file:</p> <pre><code>{\"eccodes_key\": \"#1#nonCoordinatePressure\", \"value\":\"data:BP\", \"offset\": \"const:0\", \"scale\": \"const:2\"}\n</code></pre> </li> <li> <p>You should have the following line in your mappings file:</p> <pre><code>{\"eccodes_key\": \"#1#airTemperature\", \"value\":\"data:AirTempC\"}\n{\"eccodes_key\": \"#1#dewpointTemperature\", \"value\":\"data:DewPointTempC\"}\n</code></pre> </li> <li> <p><code>{\"eccodes_key\": \"#1#airTemperature\", \"value\":\"data:AirTempC\", \"offset\": \"const:273.15\", \"scale\": \"const:0\"}</code></p> </li> <li> <p><code>{\"eccodes_key\": \"#1#dewpointTemperature\", \"value\":\"data:DewPointTempC\", \"offset\": \"const:273.15\", \"scale\": \"const:0\"}</code></p> </li> <li> <p>The CSV data is written to BUFR by re-using:</p> <pre><code>csv2bufr data transform ex_4.csv --bufr-template mappings_4.json\n</code></pre> </li> <li> <p>The converted variables can be verified using:</p> <pre><code>bufr_dump -p WIGOS_0-454-2-AWSMULANJE_20230526T005500.bufr4 | egrep -i 'nonCoordinatePressure|airTemperature|dewpointTemperature'\n</code></pre> </li> </ol>"},{"location":"answers/csv2bufr-answers/#exercise-5","title":"Exercise 5","text":"<ol> <li> <p>When converting <code>ex_5.csv</code> to BUFR, we see the following error:</p> <pre><code>#1#pressureReducedToMeanSeaLevel: Value (102043.2) out of valid range (50000 - 100000).; Element set to missing\n#1#airTemperature: Value (25.85) out of valid range (-10 - 25).; Element set to missing\n</code></pre> </li> <li> <p>By using the following command:</p> <pre><code>bufr_dump -p WIGOS_0-454-2-AWSMULANJE_20230526T005500.bufr4 | egrep -i 'pressureReducedToMeanSeaLevel|airTemperature|dewpointTemperature'\n</code></pre> <p>which gives the following output:</p> <pre><code>pressureReducedToMeanSeaLevel=MISSING\nairTemperature=MISSING\ndewpointTemperature=289.1\n</code></pre> <p>We find that the pressure and air temperature variables are missing because, from the error found in part 1, these variables are outside of the valid range.</p> </li> <li> <p>This is personal preference.</p> </li> <li> <p>Provided the values of <code>QNH</code>, <code>AirTempC</code>, and <code>DewPointTempC</code> are within the ranges set in the previous part, the CSV file should convert to BUFR without any errors.</p> </li> </ol>"},{"location":"answers/synop2bufr-answers/","title":"Converting SYNOP data to BUFR answers","text":""},{"location":"answers/synop2bufr-answers/#exercise-1","title":"Exercise 1","text":"<ol> <li>There is 1 SYNOP report, as there is only 1 delimiter (=)</li> <li>There is 1 station</li> <li> <p>This is done using the <code>transform</code> command, for example:</p> <pre><code>synop2bufr transform --metadata station_list.csv --output-dir . message.txt\n</code></pre> </li> <li> <p>This can be done using the following command:</p> <pre><code>bufr_dump -p &lt;file.bufr4&gt; | egrep -i 'latitude|longitude'\n</code></pre> </li> </ol>"},{"location":"answers/synop2bufr-answers/#exercise-2","title":"Exercise 2","text":"<ol> <li>There are 3 SYNOP reports, as there are 3 delimiters (=)</li> <li>There are 3 stations</li> <li> <p>This is done using the <code>transform</code> command, for example:</p> <pre><code>synop2bufr transform --metadata station_list.csv --output-dir . message.txt\n</code></pre> </li> <li> <p>The number of BUFR files output is determined by the number of valid SYNOP reports in the text file, provided the station TSI of each report can be found in the station list file with a corresponding WSI</p> </li> <li> <p>This can be done using the following commands:</p> <pre><code>bufr_dump -p &lt;file.bufr4&gt; | egrep -i 'wigos'\n</code></pre> <pre><code>bufr_dump -p &lt;file.bufr4&gt; | egrep -i 'wigos'\n</code></pre> <pre><code>bufr_dump -p &lt;file.bufr4&gt; | egrep -i 'wigos'\n</code></pre> <p>Note that if you have a directory with just these 3 BUFR files, you can use Linux wildcards as follows:</p> <pre><code>bufr_dump -p *.bufr4 | egrep -i 'wigos'\n</code></pre> </li> </ol>"},{"location":"answers/synop2bufr-answers/#exercise-3","title":"Exercise 3","text":"<ol> <li>No, this is not a problem provided that there exists a row in the station list file with a station TSI matching that of the SYNOP report we are trying to convert</li> <li> <p>This is done using the <code>transform</code> command, for example:</p> <pre><code>synop2bufr transform --metadata station_list.csv --output-dir . message.txt\n</code></pre> </li> <li> <p>This can be done in one command:</p> <pre><code>bufr_dump -p &lt;file.bufr4&gt; | egrep -i 'temperature|cover|sunshine|wind'\n</code></pre> </li> </ol> <p>Of course a command for each variable can also be used.</p>"},{"location":"answers/synop2bufr-answers/#exercise-4","title":"Exercise 4","text":"<ol> <li>The SYNOP reports are missing the delimiter (<code>=</code>) that allows <code>synop2bufr</code> to distinguish one report from another</li> <li>Attempting to convert should raise the following error: <code>ERROR:synop2bufr:Delimiters (=) are not present in the string, thus unable to identify separate SYNOP reports.</code></li> </ol>"},{"location":"answers/synop2bufr-answers/#exercise-5","title":"Exercise 5","text":"<ol> <li>One of the station TSIs (<code>15015</code>) has no corresponding metadata in the file, which will prohibit synop2bufr from accessing additional necessary metadata to convert the first SYNOP report to BUFR</li> <li>The error is: <code>ERROR:synop2bufr:Missing WSI for station 15015</code></li> <li>There are 3 SYNOP reports but only 2 BUFR files have been produced. This is because one of the SYNOP reports lacked the necessary metadata as mentioned above</li> </ol>"},{"location":"cheatsheets/docker/","title":"Docker cheatsheet","text":""},{"location":"cheatsheets/docker/#overview","title":"Overview","text":"<p>Docker allows for creating virtual envronments in an isolated manner in support of virtualization of computing resources.  The basic concept behind Docker is containerization, where software can run as services, interacting with other software containers, for example.</p> <p>The typical Docker workflow involves creating and building images, which are then run as live containers.</p>"},{"location":"cheatsheets/docker/#image-management","title":"Image management","text":"<ul> <li>List available images</li> </ul> <pre><code>docker images\n</code></pre> <ul> <li>Build an image from a Dockerfile:</li> </ul> <pre><code>cat &lt;&lt; EOF &gt; Dockerfile\nFROM ubuntu:latest\n\nRUN apt-get update\nRUN apt-get install \u2013y nginx\n\nCMD [\"echo\", \"Hello from my first Docker setup!\"]\nEOF\n</code></pre> <ul> <li>Building the image:</li> </ul> <pre><code>docker build -t my-image:local .\n</code></pre> <ul> <li>Removing an image:</li> </ul> <pre><code>docker rmi my-image:local\n</code></pre>"},{"location":"cheatsheets/docker/#volume-management","title":"Volume Management","text":"<ul> <li>List all created volumes:</li> </ul> <pre><code>docker volume ls\n</code></pre> <ul> <li>Create a volume:</li> </ul> <pre><code>docker volume create my-volume\n</code></pre> <ul> <li>Display detailed information on a volume:</li> </ul> <pre><code>docker volume inspect my-volume\n</code></pre> <ul> <li>Remove a volume:</li> </ul> <pre><code>docker volume rm my-volume\n</code></pre> <ul> <li>Remove all unused volumes:</li> </ul> <pre><code>docker volume prune\n</code></pre>"},{"location":"cheatsheets/docker/#container-management","title":"Container Management","text":"<ul> <li>Create a container from an image, with an interactive terminal (<code>-it</code>) and a mounted volume (<code>v</code>):</li> </ul> <pre><code>docker run -it -v ${pwd}:/app my-image:local\n</code></pre> <ul> <li>Display a list of currently running containers:</li> </ul> <pre><code>docker ps\n</code></pre> <ul> <li>List of all containers:</li> </ul> <pre><code>docker ps -a\n</code></pre> <ul> <li>Start a container:</li> </ul> <pre><code>docker start my-image:local  # starts a new container\n</code></pre> <ul> <li>Enter the interactive terminal of a running container:</li> </ul> <p>Tip</p> <p>use <code>docker ps</code> to use the container id in the command below</p> <pre><code>docker exec -it my-container /bin/bash\n</code></pre> <ul> <li>Remove a container</li> </ul> <pre><code>docker rm my-container\n</code></pre> <ul> <li>Remove a running container:</li> </ul> <pre><code>docker rm -f my-container\n</code></pre>"},{"location":"cheatsheets/linux/","title":"Linux cheatsheet","text":""},{"location":"cheatsheets/linux/#overview","title":"Overview","text":"<p>The basic concepts of working in a Linux operating system are files and directories (folders) organized in a tree structure within an environment.</p> <p>Once you login to a Linux system, you are working in a shell in which you can work on files and directories, by executing commands which are installed on the system.  The Bash shell is a common and popular shell which is typically found on Linux systems.</p>"},{"location":"cheatsheets/linux/#bash","title":"Bash","text":""},{"location":"cheatsheets/linux/#directory-navigation","title":"Directory Navigation","text":"<ul> <li>Entering an absolute directory:</li> </ul> <pre><code>cd /dir1/dir2\n</code></pre> <ul> <li>Entering a relative directory:</li> </ul> <pre><code>cd ./somedir\n</code></pre> <ul> <li>Move one directory up:</li> </ul> <pre><code>cd ..\n</code></pre> <ul> <li>Move two directories up:</li> </ul> <pre><code>cd ../..\n</code></pre> <ul> <li>Move to your \"home\" directory:</li> </ul> <pre><code>cd -\n</code></pre>"},{"location":"cheatsheets/linux/#file-management","title":"File Management","text":"<ul> <li>Listing files in the current directory:</li> </ul> <pre><code>ls\n</code></pre> <ul> <li>Listing files in the current directory with more detail:</li> </ul> <pre><code>ls -l\n</code></pre> <ul> <li>List the root of the filessystem:</li> </ul> <pre><code>ls -l /\n</code></pre> <ul> <li>Create an empty file:</li> </ul> <pre><code>touch foo.txt\n</code></pre> <ul> <li>Create a file from an <code>echo</code> command:</li> </ul> <pre><code>echo \"hi there\" &gt; test-file.txt\n</code></pre> <ul> <li>Copy a file:</li> </ul> <pre><code>cp file1 file2\n</code></pre> <ul> <li>Wildcards: operate on file patterns:</li> </ul> <pre><code>ls -l fil*  # matches file1 and file2\n</code></pre> <ul> <li>Concatenate two files into a new file called <code>newfile</code>:</li> </ul> <pre><code>cat file1 file2 &gt; newfile\n</code></pre> <ul> <li>Append another file into <code>newfile</code></li> </ul> <pre><code>cat file3 &gt;&gt; newfile\n</code></pre> <ul> <li>Delete a file:</li> </ul> <pre><code>rm newfile\n</code></pre> <ul> <li>Delete all files with the same file extension:</li> </ul> <pre><code>rm *.dat\n</code></pre> <ul> <li>Create a directory</li> </ul> <pre><code>mkdir dir1\n</code></pre>"},{"location":"cheatsheets/linux/#chaining-commands-together-with-pipes","title":"Chaining commands together with pipes","text":"<p>Pipes allow a user to send the output of one command to another using the pipe <code>|</code> symbol:</p> <pre><code>echo \"hi\" | sed 's/hi/bye/'\n</code></pre> <ul> <li>Filtering command outputs using grep:</li> </ul> <pre><code>echo \"id,title\" &gt; test-file.txt\necho \"1,birds\" &gt;&gt; test-file.txt\necho \"2,fish\" &gt;&gt; test-file.txt\necho \"3,cats\" &gt;&gt; test-file.txt\n\ncat test-file.txt | grep fish\n</code></pre> <ul> <li>Ignoring case:</li> </ul> <pre><code>grep -i FISH test-file.txt\n</code></pre> <ul> <li>Count matching lines:</li> </ul> <pre><code>grep -c fish test-file.txt\n</code></pre> <ul> <li>Return outputs not containing keyword:</li> </ul> <pre><code>grep -v birds test-file.txt\n</code></pre> <ul> <li>Count the number of lines in <code>test-file.txt</code>:</li> </ul> <pre><code>wc -l test-file.txt\n</code></pre> <ul> <li>Display output one screen at a time:</li> </ul> <pre><code>more test-file.txt\n</code></pre> <p>...with controls:</p> <ul> <li>Scroll down line by line: enter</li> <li>Go to next page: space bar</li> <li> <p>Go back one page: b</p> </li> <li> <p>Display the first 3 lines of the file:</p> </li> </ul> <pre><code>head -3 test-file.txt\n</code></pre> <ul> <li>Display the last 2 lines of the file:</li> </ul> <pre><code>tail -2 test-file.txt\n</code></pre>"},{"location":"cheatsheets/wis2box/","title":"WIS2 in a box cheatsheet","text":""},{"location":"cheatsheets/wis2box/#overview","title":"Overview","text":"<p>wis2box runs as a suite of Docker Compose commands.  The <code>wis2box-ctl.py</code> command is a utility (written in Python) to run Docker Compose commands easily.</p>"},{"location":"cheatsheets/wis2box/#wis2box-command-essentials","title":"wis2box command essentials","text":""},{"location":"cheatsheets/wis2box/#building","title":"Building","text":"<ul> <li>Build all of wis2box:</li> </ul> <pre><code>python3 wis2box-ctl.py build\n</code></pre> <ul> <li>Build a specific wis2box Docker image:</li> </ul> <pre><code>python3 wis2box-ctl.py build wis2box-management\n</code></pre> <ul> <li>Update wis2box:</li> </ul> <pre><code>python3 wis2box-ctl.py update\n</code></pre>"},{"location":"cheatsheets/wis2box/#starting-and-stopping","title":"Starting and stopping","text":"<ul> <li>Start wis2box:</li> </ul> <pre><code>python3 wis2box-ctl.py start\n</code></pre> <ul> <li>Stop wis2box:</li> </ul> <pre><code>python3 wis2box-ctl.py stop\n</code></pre> <ul> <li>Verify all wis2box containers are running:</li> </ul> <pre><code>python3 wis2box-ctl.py status\n</code></pre> <ul> <li>Login to a wis2box container (wis2box-management by default):</li> </ul> <pre><code>python3 wis2box-ctl.py login\n</code></pre> <ul> <li>Login to a specific wis2box container:</li> </ul> <pre><code>python3 wis2box-ctl.py login wis2box-api\n</code></pre>"},{"location":"cheatsheets/wis2box/#design-time-commands-metadata-management-and-publishing","title":"Design time commands (metadata management and publishing)","text":"<p>Note</p> <p>You must be logged into the wis2box-management container to run the below commands</p> <ul> <li>Publish discovery metadata:</li> </ul> <pre><code>wis2box metadata discovery publish /path/to/discovery-metadata-file.yml\n</code></pre> <ul> <li>Publish station metadata:</li> </ul> <pre><code>wis2box metadata station publish-collection\n</code></pre> <ul> <li>Add a dataset of observation collections from discovery metadata:</li> </ul> <pre><code>wis2box data add-collection /path/to/discovery-metadata-file.yml\n</code></pre> <ul> <li>Ingest data into the wis2box-incoming bucket to trigger processing and publishing:</li> </ul> <pre><code>wis2box data ingest --topic-hierarchy topic.hierarchy.path --path /path/to/directory/of/data/files\n</code></pre>"},{"location":"cheatsheets/yaml/","title":"YAML cheatsheet","text":""},{"location":"cheatsheets/yaml/#overview","title":"Overview","text":"<p>Many wis2box configuration files are managed in YAML (YAML Ain't Markup Language) format.  YAML allows for flexible configurations using indentation to do grouping and nesting.</p>"},{"location":"cheatsheets/yaml/#indentation","title":"Indentation","text":"<p>YAML is characterized by indentatation.  It is important to ensure consistet indentatation in a YAML fileiont.</p> <p>It is recommended to use 4 spaces for a default indentation level.</p> <p>It is also strongly recommended to NOT use tabs for indentation.</p>"},{"location":"cheatsheets/yaml/#a-simple-yaml-file","title":"A simple YAML file:","text":"<pre><code>my-configuration:  # &lt;- this is a section\n# this is a comment\n# you can add comments in this manner as you wish\nsection:  # &lt;- this is nested section\nsubsection:  # &lt;- this is another nested section\nvalue1: 123  # an integer\nvalue2: 1.23  # a float\nvalue3: '123'  # a number forced into a string\nvalue4: my value  # a string (does not need quoting)\nvalue4: [1, 2, 3, 4]  # an array/list\n\n# lists can contain any data type, including more lists or sections\nmy-list:  # another list, same result as value4 above\n- item 1\n- item 2\n- item 3\n</code></pre>"},{"location":"practical-sessions/accessing-your-student-vm/","title":"Accessing your student VM","text":""},{"location":"practical-sessions/accessing-your-student-vm/#introduction","title":"Introduction","text":"<p>As part of locally run wis2box training sessions, you can access your personal student VM on the local training network named \"WIS2-training\".</p> <p>Note</p> <p>If you want to run this training outside of a local training session, you can provide your own instance using any Cloud Provider:</p> <ul> <li>GCP (Google Cloud Platform) VM instance <code>e2-medium</code></li> <li>AWS (Amazon Web Services)\u00a0 ec2-instance <code>t3a.medium</code> </li> <li>Azure (Microsoft) Azure Virtual Machine <code>standard_b2s</code></li> </ul> <p>Select Ubuntu Server 20.0.4 LTS as OS and run the setup script available in student-vm-setup.zip on your instance to ensure you have all required software.</p> <p>If you are using the student VM provided during local WIS2 training sessions, the required software will already be installed.</p> <p>Note</p> <p>The student-VMs provided during WIS2 local training sessions have the following command-line editors pre-installed:</p> <ul> <li>vi</li> <li>vim</li> <li>nano</li> <li>emacs</li> </ul>"},{"location":"practical-sessions/accessing-your-student-vm/#connect-to-your-student-vm-on-the-local-training-network","title":"Connect to your student VM on the local training network","text":"<p>Use the following configuration to connect your PC on the local WiFi broadcasted in the room during WIS2 training:</p> <ul> <li>SSID: WIS2-training</li> <li>password: dataismagic!</li> </ul> <p>Use an SSH client to connect to your student VM using the following:</p> <ul> <li>Host: (provided during in-person training)</li> <li>Port: 22</li> <li>Username: (provided during in-person training)</li> <li>Password: wis2training (default password to be changed after logging in)</li> </ul> <p>Tip</p> <p>Contact a trainer if you are unsure about the hostname/username or have issues connecting.</p> <p>Once connected, please change your password to ensure others cannot access your VM:</p> <pre><code>limper@student-vm:~$ passwd\nChanging password for testuser.\nCurrent password:\nNew password:\nRetype new password:\npasswd: password updated successfully\n</code></pre>"},{"location":"practical-sessions/accessing-your-student-vm/#verify-software-versions","title":"Verify software versions","text":"<p>To be able to practice conversion to BUFR, the student VM comes with ecCodes, synop2bufr and csv2bufr pre-installed:</p> <p>Check the ecCodes version via the <code>bufr_dump</code> command:</p> <p><pre><code>bufr_dump -V\n</code></pre> returns: <pre><code>ecCodes Version 2.28.0\n</code></pre></p> <p>Check synop2bufr version: <pre><code>synop2bufr --version\n</code></pre> returns: <pre><code>synop2bufr, version 0.4.1\n</code></pre></p> <p>Check csv2bufr version: <pre><code>csv2bufr --version\n</code></pre> returns: <pre><code>csv2bufr, version 0.6.3\n</code></pre></p> <p>To be able to run wis2box, the student VM also comes with Python Docker and Docker Compose pre-installed. </p> <p>Check docker version: <pre><code>docker --version\n</code></pre> returns: <pre><code>Docker version 20.10.17, build 100c701\n</code></pre></p> <p>Check Docker Compose version: <pre><code>docker-compose --version\n</code></pre> returns: <pre><code>docker-compose version 1.29.0, build unknown\n</code></pre></p> <p>Check Python version: <pre><code>python3 --version\n</code></pre> returns: <pre><code>Python 3.8.10\n</code></pre></p>"},{"location":"practical-sessions/accessing-your-student-vm/#inspect-the-exercise-materials","title":"Inspect the exercise materials","text":"<p>Inspect the contents of your home directory; these are the materials used as part of the training and practical sessions.</p> <p><pre><code>ls ~/\n</code></pre> returns: <pre><code>exercise-materials  wis2box-1.0b4\n</code></pre></p> <p>To access the material on your local machine rather than from the command line, you can use SCP. Using WinSCP, you can create a new SCP connection to your VM as follows:</p> <p></p> <p>And you should be able to see the following content:</p> <p></p>"},{"location":"practical-sessions/accessing-your-student-vm/#exercise-1-editing-files-on-your-student-vm","title":"Exercise 1: Editing files on your Student VM","text":"<p>Connect to your Student VM using WinSCP and browse into the directory: <code>~/exercise-materials/accessing-your-student-vm/</code></p> <p>Right-click on the file <code>hello_world.txt</code> and select Edit -&gt; Internal editor.  Edit this file by adding a message of your own and save your changes.</p> <p></p> <p>From within your SSH client check the content of the file <code>~/exercise-materials/accessing-your-student-vm/hello_world.txt</code>:</p> <p><pre><code>cat ~/exercise-materials/accessing-your-student-vm/hello_world.txt\n</code></pre> And confirm you see the changes you made in the file.</p> <p>During the exercises you will be asked to edit files. It is up to you if you prefer to edit files from the command line in your SSH client (using <code>vi</code>/<code>vim</code>/<code>nano</code>/<code>emacs</code>) or using WinSCP.</p>"},{"location":"practical-sessions/accessing-your-student-vm/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>access your student VM over SSH and WinSCP</li> <li>verify the required software for the practical exercises is installed</li> <li>verify you have access to exercise materials for this training on your local student VM</li> </ul>"},{"location":"practical-sessions/configuring-data-mappings/","title":"Configuring data mappings","text":""},{"location":"practical-sessions/configuring-data-mappings/#introduction","title":"Introduction","text":"<p>wis2box uses a number of configuration files to allow for a simple setup of the system.  At the heart of wis2box is data ingest and publishing, which are driven by wis2box data mappings.  The basic concept of data mappings is configuring a WIS2 topic to a defined ingest and publish workflow and files/templates.  In this session, you will work on adding to the data mappings in support of publishing your data via wis2box.</p>"},{"location":"practical-sessions/configuring-data-mappings/#preparation","title":"Preparation","text":"<p>Login to your student VM</p>"},{"location":"practical-sessions/configuring-data-mappings/#add-csv-data","title":"Add CSV data","text":"<p>Here's how to add data mapping for wis2box to process CSV data.  Inspect the contents of the sample SYNOP CSV data mapping:</p> <pre><code>cat ~/wis2box-1.0b4/synop-csv-mappings.yml\n</code></pre> <p>Question</p> <p>What topic is defined in this mapping?  What values of the topic are placeholders to be updated later in this session?</p> <p>Copy and paste the above file contents into your file <code>~/wis2box-data/data-mappings.yml</code></p> <p>Update the <code>[country]</code> and <code>[centre_id]</code> values in your new/added data mapping.  Use your username as the <code>centre_id</code> topic.</p> <p>Tip</p> <p>The <code>country</code> value should match one of the countries in the country list of the WIS2 Topic Hierarchy.</p> <p>Note</p> <p>Centre ids will be officially managed and introduced as part of the WIS2 Topic Hierarchy throughout the WIS2 Pilot Phase, at which point each centre's id will be in the centre_id list of the WIS2 Topic Hierarchy.  <code>centre_id</code> values should be lower case and contain no accents or special characters. Dashes should be used instead of underscores.</p> <p>Note</p> <p>The <code>file-pattern</code> values throughout the data mapping provide a regular expression to be able to match filenames.  Ensure your filenames are formatted as per the regular expression in the new data mapping, to include <code>WIGOS_</code> as a fixed value, followed by the WIGOS Station Identifier (WSI), followed by an underscore (<code>_</code>), as well as any other information (i.e. datestamp).  Ensure the file extension is <code>.csv</code>.  A real world example would be <code>WIGOS_0-454-2-AWSBALAKA_2021-11-18T0955.csv</code>.</p> <p>Tip</p> <p>Remember your dataset topic for the WIS2 discovery metadata exercise.</p>"},{"location":"practical-sessions/configuring-data-mappings/#restart-wis2box","title":"Restart wis2box","text":"<p>In order for data mappings to take effect, restart wis2box as follows:</p> <pre><code>python3 wis2box-ctl.py restart\n</code></pre>"},{"location":"practical-sessions/configuring-data-mappings/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>inspect the live wis2box data mappings</li> <li>add a new data mapping</li> <li>update the <code>country</code> and <code>centre_id</code> values add a new data mapping</li> <li>update the <code>file-pattern</code> value to match your data filename convention</li> </ul>"},{"location":"practical-sessions/configuring-station-metadata/","title":"Configuring station metadata","text":""},{"location":"practical-sessions/configuring-station-metadata/#introduction","title":"Introduction","text":"<p>wis2box uses a fixed station metadata list that is used as part of its runtime operation.  Only data for stations configured in the wis2box station list will be published on your wis2box broker. The WIGOS Station Identifier (WSI) is used as the unique reference of the station which produced a specific set of observation data.</p>"},{"location":"practical-sessions/configuring-station-metadata/#preparation","title":"Preparation","text":"<p>Login to your student VM using SSH.</p> <p>Ensure wis2box is running:</p> <pre><code>cd ~/wis2box-1.0b4\npython3 wis2box-ctl.py start\npython3 wis2box-ctl.py status\n</code></pre>"},{"location":"practical-sessions/configuring-station-metadata/#update-the-wis2box-station-list","title":"Update the wis2box station list","text":"<p>Pre-select a few stations in your country that you would consider for data publishing on WIS2. If you want to ingest your own data sample later during the WIS2 training, make sure to add the stations corresponding to your data.</p> <p>Edit the file <code>~/wis2box-data/metadata/station/station_list.csv</code>:</p> <p>For each new station, add a row to the end of the file with the following values:</p> <ul> <li><code>station_name</code>: the human readable name of the station</li> <li><code>wigos_station_identifier</code>: the WSI issued for the station</li> <li><code>traditional_station_identifier</code>: the traditional station identifier if a WSI does not exist</li> <li><code>facility_type</code>: the station/platform type (use Land (fixed) for land stations)</li> <li><code>latitude</code>: the latitude, in decimal degrees</li> <li><code>longitude</code>: the longitude, in decimal degrees</li> <li><code>elevation</code>: station elevation, in metres above sea level</li> <li><code>territory_name</code>: the human readable country name</li> <li><code>wmo_region</code>: the Roman numeral of your country based on WMO Regional Associations</li> </ul> <p>Tip</p> <p>Ensure that latitude and longitude values are correctly signed (for example, use the minus sign [<code>-</code>] for southern or western hemispheres.</p>"},{"location":"practical-sessions/configuring-station-metadata/#using-data-from-oscar","title":"Using data from OSCAR","text":"<p>It is recommended to use station information from the WMO OSCAR/Surface system where available.</p> <p>The script <code>~/exercise-materials/create-station-list/oscar2wis2box.py</code> can be used to add stations to your station list if they are available in OSCAR/Surface.</p> <p>For example to add the stations with WIGOS-IDs=0-20000-0-78970, 0-20000-0-78969 and 0-20000-0-78962 to your <code>station_list.csv</code>, run the following commands: </p> <pre><code>python3 ~/exercise-materials/station-list/oscar2wis2box.py 0-20000-0-78970 &gt;&gt; ~/wis2box-data/metadata/station/station_list.csv\npython3 ~/exercise-materials/station-list/oscar2wis2box.py 0-20000-0-78969 &gt;&gt; ~/wis2box-data/metadata/station/station_list.csv\npython3 ~/exercise-materials/station-list/oscar2wis2box.py 0-20000-0-78962 &gt;&gt; ~/wis2box-data/metadata/station/station_list.csv\n</code></pre>"},{"location":"practical-sessions/configuring-station-metadata/#review-your-station-list","title":"Review your station list","text":"<p>Check the content of your station list from the command line as follows:</p> <pre><code>cat ~/wis2box-data/metadata/station/station_list.csv\n</code></pre> <p>Or open the file in WinSCP.</p> <p>Keep adding lines to <code>station_list.csv</code> and ensure you have at least three stations defined.</p>"},{"location":"practical-sessions/configuring-station-metadata/#publishing-station-metadata","title":"Publishing station metadata","text":"<p>Login in to the wis2box-management container:</p> <pre><code>cd ~/wis2box-1.0b4/\npython3 wis2box-ctl.py login\n</code></pre> <p>Run the following command to publish your station metadata:</p> <pre><code>wis2box metadata station publish-collection\n</code></pre> <p>Ensure that your new station metadata was published to the API, by navigating to <code>http://&lt;your-host&gt;.wis2.training/oapi/collections/stations/items</code>:</p> <p></p> <p>Click on your station metadata record and inspect the content, noting how it relates to the content of the <code>station_list.csv</code> you have updated.</p>"},{"location":"practical-sessions/configuring-station-metadata/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>update station metadata</li> <li>publish station metadata</li> </ul>"},{"location":"practical-sessions/configuring-wis2-discovery-metadata/","title":"Configuring WIS2 discovery metadata","text":""},{"location":"practical-sessions/configuring-wis2-discovery-metadata/#introduction","title":"Introduction","text":"<p>As described in the overviews, WIS2 requires discovery metadata to be provided describing your data to be shared to WIS2 Global Services.  This session will walk you through creating and publishing discovery metadata from wis2box from a configuration file.</p>"},{"location":"practical-sessions/configuring-wis2-discovery-metadata/#preparation","title":"Preparation","text":"<p>Ensure you are running MQTT Explorer and you are connected to the broker on your student VM before continuing.</p> <p>Login to your student VM using your SSH-client.</p>"},{"location":"practical-sessions/configuring-wis2-discovery-metadata/#creating-discovery-metadata","title":"Creating discovery metadata","text":"<p>Copy the test discovery metadata into your own file (you may name the file whatever you wish):</p> <pre><code>cd ~/wis2box-1.0b4/\ncp examples/config/surface-weather-observations.yml ~/wis2box-data/my-discovery-metadata.yml\n</code></pre> <p>Inspect the sample discovery metadata:</p> <pre><code>more ~/wis2box-data/my-discovery-metadata.yml\n</code></pre> <p>Note</p> <p>All values in the discovery metadata configuration are required and should be included.</p> <p>Question</p> <p>How does line 3 of your discovery metadata file relate to the new data mapping in the previous session?</p> <p>Update the following values in the discovery metadata configuration:</p> <ul> <li><code>wis2box.topic_hierarchy</code>: the topic hierarchy that categorizes the data (this value should be the same as the definition in your newly created data mapping).</li> <li><code>wis2box.country</code>: 3-letter country code in lower case</li> <li><code>wis2box.centre_id</code>: your centre id as defined in the previous exercise</li> <li><code>metadata.identifier</code>: a unique identifier consisting of <code>urn:x-wmo:md:[country]:[centre_id]:[dataset_name]</code>, where <code>[dataset-name]</code> can be any name of your choosing.  Remember this value for API validation later on in this exercise</li> <li><code>identification.title</code>: a human readable title describing your data</li> <li><code>identification.abstract</code>: a human readable description describing your data</li> <li><code>identification.dates.creation</code>: when the discovery metadata was created (today's date)</li> <li><code>identification.extents.spatial (bbox)</code>: the bounding box coordinates of your data (minimum longitude, minimum latitude, maximum longitude, maximum latitude), in decimal degrees</li> <li><code>identification.extents.temporal (begin)</code>: the begin and end time of your data (keeping the end time to <code>null</code> is suitable to ongoing observations)</li> <li><code>contact.pointOfContact</code>: your organization's point of contact information</li> </ul> <p>Tip</p> <p>The configuration is based on the YAML format.  Consult the YAML cheatsheet for more information.</p> <p>Tip</p> <p>Ensure that bbox values are correctly signed (for example, use the minus sign [<code>-</code>] for southern or western hemispheres.</p> <p>Tip</p> <p>The following tools can be valuable for deriving your <code>identification.extents.spatial.bbox</code>:</p> <ul> <li>https://gist.github.com/graydon/11198540</li> <li>http://bboxfinder.com</li> <li>https://boundingbox.klokantech.com</li> </ul>"},{"location":"practical-sessions/configuring-wis2-discovery-metadata/#publishing-discovery-metadata","title":"Publishing discovery metadata","text":"<p>First login to the wis2box-management container:</p> <pre><code>python3 wis2box-ctl.py login\n</code></pre> <p>Run the following command to publish your discovery metadata:</p> <pre><code>wis2box metadata discovery publish /data/wis2box/my-discovery-metadata.yml\n</code></pre> <p>Ensure that your discovery metadata was published to the API, by navigating to <code>http://&lt;your-host&gt;/oapi/collections/discovery-metadata</code>.</p> <p>Ensure that your discovery metadata was also published to the broker, by looking for a new metadata message in MQTT Explorer.</p> <p>Question</p> <p>Do you see your new discovery metadata in the API?</p> <p>Click on your discovery metadata record and inspect the content, noting how it relates to the discovery metadata configuration created earlier in this session.</p> <p>Update the title of your discovery metadata, and re-publish:</p> <pre><code>vi /data/wis2box/my-discovery-metadata.yml\nwis2box metadata discovery publish /data/wis2box/my-discovery-metadata.yml\n</code></pre> <p>Ensure that your discovery metadata updates were published to the API, by refreshing the page to your discovery metadata.</p> <p>Question</p> <p>Are you able to see the updates you made in the configuration?</p> <p>Feel free to update additional values and re-publishing your discovery metadata to get a better idea of how and where discovery metadata content is updated.</p>"},{"location":"practical-sessions/configuring-wis2-discovery-metadata/#publishing-your-dataset-to-the-api","title":"Publishing your dataset to the API","text":"<p>Run the below command to add the data to the API:</p> <pre><code>wis2box data add-collection /data/wis2box/my-discovery-metadata.yml\n</code></pre> <p>Ensure that your dataset was published to the API, by navigating to <code>http://&lt;your-host&gt;/oapi/collections/&lt;metadata.identifier&gt;</code>.</p> <p>Question</p> <p>Do you see your new dataset in the API?</p> <p>Question</p> <p>Do you see any data coming from your new dataset in the API?  If not, why not?</p>"},{"location":"practical-sessions/configuring-wis2-discovery-metadata/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>create discovery metadata</li> <li>publish discovery metadata</li> <li>update and re-publish discovery metadata</li> </ul>"},{"location":"practical-sessions/connecting-to-mqtt/","title":"Connecting to WIS2 over MQTT","text":""},{"location":"practical-sessions/connecting-to-mqtt/#introduction","title":"Introduction","text":"<p>WIS2 uses the MQTT protocol to advertise the availability of weather/climate/water data. The WIS2 Global Broker subscribes to all WIS2 Nodes in the network and republishes the messages it receives. The Global Cache subscribes to the Global Broker, downloads the data in the message and then republishes the message on the <code>cache</code> topic with a new URL.  The Global Discovery Catalogue publishes discovery metadata from the Broker and provides a search API.</p> <p>As part of the WIS2 Pilot Phase in 2023, the following Global Broker services are available:</p>"},{"location":"practical-sessions/connecting-to-mqtt/#meteo-france","title":"M\u00e9t\u00e9o-France","text":"<ul> <li>host: globalbroker.meteo.fr</li> <li>port: 8883</li> <li>username: everyone</li> <li>password: everyone</li> </ul>"},{"location":"practical-sessions/connecting-to-mqtt/#cma","title":"CMA","text":"<ul> <li>host: gb.wis.cma.cn</li> <li>port: 8883</li> <li>username: everyone</li> <li>password: everyone</li> </ul> <p>In this practical session you will learn how to use the MQTT Explorer tool to review the topics available on this Global Broker and be able to display WIS2 notification messages.</p>"},{"location":"practical-sessions/connecting-to-mqtt/#using-mqtt-explorer-to-connect-to-the-global-broker","title":"Using MQTT Explorer to connect to the Global Broker","text":"<p>One way to view messages published by this Global Broker is using the MQTT Explorer which can be downloaded from the MQTT Explorer website.</p> <p>Open MQTT Explorer and add a new connection as follows:</p> <p></p> <p>Click on the 'ADVANCED' button and add the following topics to subscribe to:</p> <p></p> <p>Note</p> <p>When setting up MQTT subscriptions you can use the following wildcards:</p> <ul> <li>Single-level (+): a single-level wildcard replaces one topic level</li> <li>Multi-level (#): a multi-level wildcard replaces multiple topic levels</li> </ul> <p>Click 'BACK', then 'SAVE' to save your connection and subscription details.  Then click 'CONNECT':</p> <p>At this point, the following should appear in the MQTT Explorer session:</p> <p></p> <p>You are now ready to start exploring the WIS2 topics and message structure and answer the following questions:</p> <p>Review the WIS2 topic structure</p> <p>Use MQTT to browse topic structure under the <code>origin</code> and <code>cache</code> topics.</p> <p>How can we distinguish the originating country providing the data?</p> <p>How many countries are sharing data?</p> <p>Zambia data from origin</p> <p>Find the latest message received in the following topic:</p> <p><code>origin/a/wis2/zmb/zambia_met_service/data/core/weather/surface-based-observations/synop</code></p> <p>You can view the content of the WIS2 message in the \"Value\" section on the right hand side.</p> <p>What is the timestamp in UTC for when this data was published?</p> <p>What is the URL from which we can download the data in BUFR format?</p> <p>Zambia data from cache</p> <p>Find the latest message received on the following topic:</p> <p><code>cache/a/wis2/zmb/zambia_met_service/data/core/weather/surface-based-observations/synop</code></p> <p>What is the timestamp in UTC for when this data was published?</p> <p>What is the URL we can use to download the data?  What is the difference between this URL and the URL in the previous question?</p> <p>Note</p> <p>MQTT Explorer is a helpful tool to review the topic structure for a given MQTT broker and visually work with the MQTT protocol. There exist many MQTT client and server software. </p> <p>To work with MQTT programmatically (for example, in Python), you can use MQTT client libraries such as paho-mqtt to connect to an MQTT broker and process incoming messages.</p>"},{"location":"practical-sessions/connecting-to-mqtt/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>Congratulations!  In this practical session, you learned:</p> <ul> <li>how to subscribe to WIS2 Global Broker services using MQTT Explorer</li> <li>the WIS2 topic structure</li> <li>the WIS2 notification message structure</li> <li>the difference between Global Broker messages published on the <code>origin</code> and <code>cache</code> topics</li> </ul>"},{"location":"practical-sessions/converting-csv-data-to-bufr/","title":"Converting CSV data to BUFR","text":""},{"location":"practical-sessions/converting-csv-data-to-bufr/#introduction","title":"Introduction","text":"<p>CSV data is a commonly used format for recording tabular data.  <code>csv2bufr</code> is a tool to help convert CSV to BUFR data.</p> <p>In this session you will learn to create BUFR data from CSV, using custom and flexible configuration (mappings) in support of meeting WMO GBON requirements.</p>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#preparation","title":"Preparation","text":"<p>Warning</p> <p>Ensure that you are logged into your student VM.</p> <p>Navigate to the <code>exercise-materials/csv2bufr-exercises</code> directory and make sure that the exercises directories are there.</p> <pre><code>cd ~/exercise-materials/csv2bufr-exercises\nls\n</code></pre> <p>Tip</p> <p>You should be able to see the following directories <code>answers  ex_1  ex_2  ex_3  ex_4  ex_5</code></p>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#csv2bufr-primer","title":"csv2bufr primer","text":""},{"location":"practical-sessions/converting-csv-data-to-bufr/#necessary-csv-data","title":"Necessary CSV data","text":"<p>There are some requirements on the data that must be present in the CSV file:</p> <ul> <li>WIGOS Station Identifier, either in 1 column or split over 4 columns for each component as follows:</li> <li>Observation year</li> <li>Observation month</li> <li>Observation day</li> <li>Observation hour</li> <li>Observation minute</li> <li>Latitude</li> <li>Longitude</li> <li>Station height</li> <li>Barometer height</li> </ul> <p>Note</p> <p>Notice that the datetime of the observation is split into 5 different columns (from most to least significant).</p> <p>Below are essential <code>csv2bufr</code> commands and configurations:</p>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#mappings-create","title":"mappings Create","text":"<p>The <code>mappings create</code> command creates an empty BUFR mapping template JSON file, which maps CSV column headers to their corresponding ecCodes element:</p> <pre><code>csv2bufr mappings create &lt;BUFR descriptors&gt; --output &lt;my_template.json&gt;\n</code></pre> <p>For more information, see the following example.</p>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#data-transform","title":"data transform","text":"<p>The <code>data transform</code> command converts a CSV file to BUFR format:</p> <pre><code>csv2bufr data transform --bufr-template &lt;my_template.json&gt; --output-dir &lt;./my_directory&gt; &lt;my_data.csv&gt;\n</code></pre> <p>Note</p> <p>The output directory is not required, and by default is the current working directory.</p>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#eccodes-bufr-refresher","title":"ecCodes BUFR refresher","text":""},{"location":"practical-sessions/converting-csv-data-to-bufr/#bufr_dump","title":"bufr_dump","text":"<p>The <code>bufr_dump</code> function will allow you to inspect the BUFR files created from the conversion. It has numerous options, the following will be most applicable to the exercises:</p> <pre><code>bufr_dump -p &lt;my_bufr.bufr4&gt;\n</code></pre> <p>This will display the content of your BUFR on screen.  If you are interested in the values taken by a variable in particular, use the <code>egrep</code> command:</p> <pre><code>bufr_dump -p &lt;my_bufr.bufr4&gt; | egrep -i temperature\n</code></pre> <p>This will display the variables related to temperature in your BUFR data.  If you want to do this for multiple types of variables, filter the output using a pipe (<code>|</code>):</p> <pre><code>bufr_dump -p &lt;my_bufr.bufr4&gt; | egrep -i 'temperature|wind'\n</code></pre>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#inspecting-csv-data-and-bufr-conversion","title":"Inspecting CSV data and BUFR conversion","text":""},{"location":"practical-sessions/converting-csv-data-to-bufr/#exercise-1-converting-a-csv-file-to-bufr","title":"Exercise 1: Converting a CSV file to BUFR","text":"<p>In this exercise we will look at a pre-configured mapping file for the CSV data, and will use this to convert the data to BUFR.</p> <p>Navigate to the <code>ex_1</code> directory:</p> <pre><code>cd ~/exercise-materials/csv2bufr-exercises/ex_1\n</code></pre> <p>and open the CSV data <code>ex_1.csv</code>.</p> <ol> <li>How many header rows are there in this data?</li> <li>Which row contains the column names?</li> </ol> <p>Now open the mappings file <code>mappings_1.json</code>.</p> <p>Note</p> <p>csv2bufr mappings files have no set file extension, however it recommended to use <code>.json</code>.</p> <ol> <li> <p>Verify that <code>\"number_header_rows\"</code> and <code>\"column_names_row\"</code> are the same as your answers above.</p> </li> <li> <p>Locate each of the CSV column names in this mappings file.</p> </li> <li> <p>By the <code>data transform</code> command, use the mappings file to convert this CSV data to BUFR.</p> </li> <li> <p>Use bufr_dump to find the latitude and longitude value stored in the output BUFR file. Verify these values using the CSV file.</p> </li> </ol>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#exercise-2-correcting-the-datetime-format","title":"Exercise 2: Correcting the datetime format","text":"<p>In this exercise we will investigate the correct format to present the datetime of an observation in the CSV file.</p> <p>Navigate to the <code>ex_2</code> directory:</p> <pre><code>cd ~/exercise-materials/csv2bufr-exercises/ex_2\n</code></pre> <p>and open the CSV data <code>ex_2.csv</code>.</p> <ol> <li>What are the differences in the way that the datetime is represented in this CSV file compared to the previous one?</li> </ol> <p>Now open the mappings file <code>mappings_2.json</code>. By looking at the eccodes keys related to dates and times, it should seem clear that it is not possible to map the datetime with the CSV in its current state.</p> <ol> <li> <p>Create new columns in the CSV file for each component of the datetime: <code>Year</code>, <code>Month</code>, <code>Day</code>, <code>Hour</code>, <code>Minute</code>.</p> </li> <li> <p>By the <code>data transform</code> command, use the mappings file to convert this CSV data to BUFR.</p> </li> </ol>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#exercise-3-handling-changes-to-the-csv-data","title":"Exercise 3: Handling changes to the CSV data","text":"<p>In this exercise we consider the following scenario: given the same CSV data but with different column names, how can we adjust the mappings file to convert this data to BUFR? For simplicity, we will only look at one column name change.</p> <p>Navigate to the <code>ex_3</code> directory</p> <pre><code>cd ~/exercise-materials/csv2bufr-exercises/ex_3\n</code></pre> <ol> <li>By the <code>data transform</code> command, attempt to convert the CSV data to BUFR. What error appears?</li> </ol> <p>Open the CSV data <code>ex_3.csv</code>.</p> <ol> <li>What column name has been changed?</li> </ol> <p>Open the mappings file <code>mappings_3.json</code>.</p> <ol> <li>Find the original column name in this mapping file, and change it to the new name.</li> <li>By the <code>data transform</code> command, use the mappings file to convert this CSV data to BUFR.</li> <li>Use <code>bufr_dump</code> to verify that <code>relativeHumidity</code> has the same value as the CSV data.</li> </ol>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#exercise-4-unit-conversion","title":"Exercise 4: Unit conversion","text":"<p>In this exercise, we expand on the work above by not only handling changes to column names, but also the units of the data. We achieve this by using <code>offset</code> and <code>scale</code> in the mappings file.</p> <p>Navigate to the <code>ex_4</code> directory:</p> <pre><code>cd ~/exercise-materials/csv2bufr-exercises/ex_4\n</code></pre> <p>and open the CSV data <code>ex_4.csv</code>.</p> <ol> <li>Which row are the units of the variables written?</li> </ol> <p>You should notice that <code>BP</code> now has units hPa instead of Pa. Moreover, the air temperature and dewpoint temperature now have column names <code>AirTempC</code> and <code>DewPointTempC</code>, with units C instead of K.</p> <ol> <li>What power of 10 is needed to convert hPa to Pa?</li> <li>What constant must be added to convert degrees C to K?</li> </ol> <p>Open the mappings file <code>mappings_4.json</code>. Find the lines corresponding to the variables above.</p> <ol> <li> <p>Convert <code>BP</code> to Pa by adding the following line to the right of <code>\"data:BP\"</code>:</p> <pre><code>\"offset\": \"const:0\", \"scale\": \"const:x\"\n</code></pre> <p>where <code>x</code> is your answer in part 3.</p> </li> <li> <p>Change the column names of air temperature and dewpoint temperature in the mappings file to match that of the CSV file, as you did in the previous exercise.</p> </li> <li> <p>Convert <code>AirTempC</code> to K by adding the following line to the right of <code>\"data:AirTempC\"</code>:</p> <pre><code>\"offset\": \"const:y\", \"scale\": \"const:0\"\n</code></pre> <p>where <code>y</code> is your answer in part 4.</p> </li> <li> <p>Convert <code>DewPointTempC</code> to K by adding the following line to the right of <code>\"data:DewPointTempC\"</code>:</p> <pre><code>\"offset\": \"const:y\", \"scale\": \"const:0\"\n</code></pre> <p>where <code>y</code> is your answer in part 4.</p> </li> <li> <p>By running the <code>csv2bufr data transform</code> command, use the mappings file to convert this CSV data to BUFR.</p> </li> <li> <p>Use the <code>bufr_dump</code> command to verify that <code>nonCoordinatePressure</code>, <code>airTemperature</code> and <code>dewpointTemperature</code> have the values you would expect after conversion.</p> </li> </ol>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#exercise-5-implementing-quality-control","title":"Exercise 5: Implementing quality control","text":"<p>In this exercise, we will implement some minimum and maximum tolerable values to prevent data of certain variables from being encoded into BUFR. To do this, we will use <code>valid_min</code> and <code>valid_max</code> in the mappings file.</p> <p>Navigate to the <code>ex_5</code> directory:</p> <pre><code>cd ~/exercise-materials/csv2bufr-exercises/ex_5\n</code></pre> <ol> <li> <p>By running the <code>csv2bufr data transform</code> command, use the mappings file to convert this CSV data to BUFR. What error occurs? Is a BUFR file created?</p> </li> <li> <p>Use the <code>bufr_dump</code> command to check the values of <code>pressureReducedToMeanSeaLevel</code>, <code>airTemperature</code> and <code>dewpointTemperature</code>. Which variables are missing, and why?</p> </li> </ol> <p>Open the mappings file <code>mappings_5.json</code>. Find the lines corresponding to the variables above. You will find the following on these lines:</p> <pre><code>\"valid_min\": \"const:a\", \"valid_max\": \"const:b\"\n</code></pre> <p>where <code>a</code> and <code>b</code> are values. These values represent the minimum and maximum tolerable extremes for encoding into BUFR. </p> <ol> <li> <p>Change <code>a</code> and <code>b</code> on each line to form a less tight range of tolerance for these variables.</p> <p>Note</p> <p>The valid minimum and maximum values should take the same units as the CSV data.</p> </li> <li> <p>By running the <code>csv2bufr data transform</code> command, use this mappings file to convert this CSV data to BUFR again. Do you notice any errors this time?</p> </li> </ol>"},{"location":"practical-sessions/converting-csv-data-to-bufr/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned:</p> <ul> <li>The basic usage of <code>csv2bufr</code></li> <li>The required structure of CSV data for conversion to BUFR</li> <li>How to update a simple csv2bufr mapping file for a variety of scenarios, including for GBON requirements, unit conversion, and quality control/range checking</li> <li>How to use <code>csv2bufr</code> on a test data file and convert to BUFR format</li> <li>How to use <code>bufr_dump</code> to verify the values of BUFR encoded variables</li> </ul>"},{"location":"practical-sessions/converting-daycli-data-to-bufr/","title":"Converting DAYCLI data to BUFR","text":""},{"location":"practical-sessions/converting-daycli-data-to-bufr/#introduction","title":"Introduction","text":"<p>Daily climate reports (DAYCLI) are a requirement for daily climate observations to monitor extremes, such as daily maximum and minimum temperature, daily total precipitation, and more. </p> <p>This session will focus on understanding the structure of a typical DAYCLI CSV file, converting it to BUFR format, and inspecting the resulting contents.</p> <p>If this data is recorded in CSV format, we can use csv2bufr to convert this data to BUFR.  Moreover, if the structure of the CSV file is correct, then one does not need to configure a mappings file for the conversion to BUFR, as a DAYCLI mapping template comes included with csv2bufr to manage such data.</p>"},{"location":"practical-sessions/converting-daycli-data-to-bufr/#preparation","title":"Preparation","text":"<p>Warning</p> <p>Ensure that you are logged into your student VM.</p> <p>Navigate to the <code>exercise-materials/daycli-exercises</code> directory.</p> <pre><code>cd ~/exercise-materials/daycli-exercises\n</code></pre>"},{"location":"practical-sessions/converting-daycli-data-to-bufr/#exercise","title":"Exercise","text":"<p>Edit the file <code>daycli.csv</code>.  Compare the column structure to that of the final slides of the presentation we just viewed.</p> <p>Convert this CSV file to BUFR using the built-in daycli mapping file:</p> <pre><code>csv2bufr data transform --bufr-template daycli --output-dir ./ daycli.csv\n</code></pre> <p>Inspect the output BUFR files using <code>bufr_dump</code> and verify the data is the same as the original DAYCLI CSV file.</p>"},{"location":"practical-sessions/converting-daycli-data-to-bufr/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>verify the structure of a typical DAYCLI CSV file</li> <li>convert this DAYCLI CSV file into BUFR using csv2bufr and the built-in daycli mapping template</li> <li>inspect the contents of the DAYCLI BUFR files created</li> </ul>"},{"location":"practical-sessions/converting-synop-data-to-bufr/","title":"Converting SYNOP data to BUFR","text":""},{"location":"practical-sessions/converting-synop-data-to-bufr/#introduction","title":"Introduction","text":"<p>Surface synoptic observations (SYNOP) data are used to report weather observations from surface stations (manned or automated).  synop2bufr is a tool to help convert SYNOP to BUFR data.  ecCodes is a package to reading and writing GRIB and BUFR formats.</p> <p>In this session you will learn about converting a SYNOP report into the WMO BUFR format using the above mentioned tools, as well as the relationship between SYNOP reports and BUFR messages.</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#preparation","title":"Preparation","text":"<p>Warning</p> <p>Ensure that you are logged into your student VM. </p> <p>Navigate to the <code>exercise-materials/synop2bufr-exercises</code> directory and make sure that the exercises directories are there.</p> <pre><code>cd ~/exercise-materials/synop2bufr-exercises\nls\n</code></pre> <p>Tip</p> <p>You should be able to see the following directories <code>answers  ex_1  ex_2  ex_3  ex_4  ex_5</code></p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#synop2bufr-primer","title":"synop2bufr primer","text":"<p>Below are essential <code>synop2bufr</code> commands and configurations:</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#transform","title":"transform","text":"<p>The <code>transform</code> function converts a SYNOP message to BUFR:</p> <pre><code>synop2bufr transform --metadata my_file.csv --output-dir ./my_directory --year message_year --month message_month my_SYNOP.txt\n</code></pre> <p>Note that if the metadata, output directory, year and month options are not specified, they will assume their default values:</p> Option Default --metadata station_list.csv --output-dir The current working directory. --year The current year. --month The current month. <p>Note</p> <p>One must be cautious using the default year and month, as the day of the month specified in the report may not correspond (e.g. June does not have 31 days).</p> <p>In the examples, the year and month are not given, so feel free to specify a date yourself or use the default values.</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#eccodes-primer","title":"ecCodes primer","text":"<p>ecCodes provides both command line tools and can be embedded in your own applications.  Below are some useful command line utilities to work with BUFR data.</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#bufr_dump","title":"bufr_dump","text":"<p>The <code>bufr_dump</code> command is a generic BUFR information tool.  It has many options, but the following will be the most applicable to the exercises:</p> <pre><code>bufr_dump -p my_bufr.bufr4\n</code></pre> <p>This will display BUFR content to your screen.  If you are interested in the values taken by a variable in particular, use the <code>egrep</code> command:</p> <pre><code>bufr_dump -p my_bufr.bufr4 | egrep -i temperature\n</code></pre> <p>This will display variables related to temperature in your BUFR data. If you want to do this for multiple types of variables, filter the output using a pipe (<code>|</code>):</p> <pre><code>bufr_dump -p my_bufr.bufr4 | egrep -i 'temperature|wind'\n</code></pre>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#inspecting-synop-data-and-bufr-conversion","title":"Inspecting SYNOP data and BUFR conversion","text":""},{"location":"practical-sessions/converting-synop-data-to-bufr/#exercise-1","title":"Exercise 1","text":"<p>Navigate to the <code>exercise-materials/synop2bufr-exercises/ex_1</code> directory and inspect the SYNOP message file message.txt:</p> <pre><code>cd ~/exercise-materials/synop2bufr-exercises/ex_1\nmore message.txt\n</code></pre> <p>Question</p> <p>How many SYNOP reports are in this file?</p> <p>Inspect the station list:</p> <pre><code>more station_list.csv\n</code></pre> <p>Question</p> <p>How many stations are listed in the station list?</p> <p>Question</p> <p>Convert <code>message.txt</code> to BUFR format.</p> <p>Tip</p> <p>See the synop2bufr primer section.</p> <p>Note</p> <p>BUFR files have no set file extension, however it is recommended to use <code>.bufr4</code>.</p> <p>Inspect the resulting BUFR data using <code>bufr_dump</code>.</p> <p>Question</p> <p>Compare the latitude and longitude values to those in the station list.</p> <p>Tip</p> <p>See the ecCodes primer section.</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#exercise-2","title":"Exercise 2","text":"<p>Navigate to the <code>exercise-materials/synop2bufr-exercises/ex_2</code> directory and inspect the SYNOP message file message.txt:</p> <pre><code>cd ~/exercise-materials/synop2bufr-exercises/ex_2\nmore message.txt\n</code></pre> <p>Question</p> <p>How many SYNOP reports are in this file?</p> <p>Inspect the station list:</p> <pre><code>more station_list.csv\n</code></pre> <p>Question</p> <p>How many stations are listed in the station list?</p> <p>Question</p> <p>Convert <code>message.txt</code> to BUFR format.</p> <p>Question</p> <p>Based on the results of the exercises in this and the previous exercise, how would you predict the number of resulting BUFR files based upon the number of SYNOP reports and stations listed in the station metadata file?</p> <p>Inspect the resulting BUFR data using <code>bufr_dump</code>.</p> <p>Question</p> <p>Check each of the output BUFR files contain different WIGOS Station Identifiers (WSI).</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#exercise-3","title":"Exercise 3","text":"<p>Navigate to the <code>exercise-materials/synop2bufr-exercises/ex_3</code> directory and inspect the SYNOP message file message.txt:</p> <pre><code>cd ~/exercise-materials/synop2bufr-exercises/ex_3\nmore message.txt\n</code></pre> <p>This SYNOP message only contains one longer report with more sections.</p> <p>Inspect the station list:</p> <pre><code>more station_list.csv\n</code></pre> <p>Question</p> <p>Is it problematic that this file contains more stations than there are reports in the SYNOP message?</p> <p>Note</p> <p>The station list file is a source of metadata for <code>synop2bufr</code> to provide the information missing in the alphanumeric SYNOP report and required in the BUFR SYNOP.</p> <p>Question</p> <p>Convert <code>message.txt</code> to BUFR format.</p> <p>Inspect the resulting BUFR data using <code>bufr_dump</code>.</p> <p>Question</p> <p>Find the following variables:</p> <ul> <li>Air temperature (K) of the report</li> <li>Total cloud cover (%) of the report</li> <li>Total period of sunshine (mins) of the report</li> <li>Wind speed (m/s) of the report</li> </ul> <p>Tip</p> <p>You may find the last command of the ecCodes primer section useful.</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#exercise-4","title":"Exercise 4","text":"<p>Navigate to the <code>exercise-materials/synop2bufr-exercises/ex_4</code> directory and inspect the SYNOP message file message.txt:</p> <pre><code>cd ~/exercise-materials/synop2bufr-exercises/ex_4\nmore message_incorrect.txt\n</code></pre> <p>Question</p> <p>What is incorrect about this SYNOP file?</p> <p>Attempt to convert <code>message_incorrect.txt</code> using <code>station_list.csv</code></p> <p>Question</p> <p>What problem(s) did you encounter with this conversion?</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#exercise-5","title":"Exercise 5","text":"<p>Navigate to the <code>exercise-materials/synop2bufr-exercises/ex_5</code> directory and inspect the SYNOP message file message.txt:</p> <pre><code>cd ~/exercise-materials/synop2bufr-exercises/ex_5\nmore message.txt\n</code></pre> <p>Attempt to convert <code>message.txt</code> to BUFR format using <code>station_list_incorrect.csv</code> </p> <p>Question</p> <p>What problem(s) did you encounter with this conversion? Considering the error presented, justify the number of BUFR files produced.</p>"},{"location":"practical-sessions/converting-synop-data-to-bufr/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned:</p> <ul> <li>the principles of SYNOP data reporting</li> <li>how to use <code>synop2bufr</code> to convert SYNOP data to BUFR format</li> <li>how to use <code>bufr_dump</code> to inspect the content of BUFR data</li> </ul>"},{"location":"practical-sessions/data-api-usage-and-queries/","title":"Data API usage and queries","text":""},{"location":"practical-sessions/data-api-usage-and-queries/#introduction","title":"Introduction","text":"<p>The wis2box API provides discovery and query access in a machine readable manager, which includes the wis2box UI.</p> <p>In this practical session you will learn how to use the data API to discovery, browse and query data that has been ingested in wis2box.</p>"},{"location":"practical-sessions/data-api-usage-and-queries/#preparation","title":"Preparation","text":"<p>Note</p> <p>Navigate to the wis2box API landing page in your web browser:</p> <p><code>http://&lt;your-host&gt;/oapi</code></p> <p></p>"},{"location":"practical-sessions/data-api-usage-and-queries/#inspecting-collections","title":"Inspecting collections","text":"<p>From the landing page, click on the 'Collections' link.</p> <p>Question</p> <p>How many dataset collections do you see on the resulting page? What do you think each collection represents?</p>"},{"location":"practical-sessions/data-api-usage-and-queries/#inspecting-stations","title":"Inspecting stations","text":"<p>From the landing page, click on the 'Collections' link, then click on the 'Stations' link.</p> <p></p> <p>Click on the 'Browse' link, then click on the 'json' link.</p> <p>Question</p> <p>How many stations are returned? Compare this number to the station list in <code>/data/wis2box/metadata/station/station_list.csv</code> file when logged into wis2box (<code>python3 wis2box-ctl.py login</code>).</p> <p>Question</p> <p>How can we query for a single station (e.g. <code>Balaka</code>)?</p> <p>Note</p> <p>The above example is based on the Malawi test data.  Try testing against the stations your have ingested as part of the exercises.</p>"},{"location":"practical-sessions/data-api-usage-and-queries/#inspecting-observations","title":"Inspecting observations","text":"<p>Note</p> <p>The above example is based on the Malawi test data.  Try testing against the observation your have ingested as part of the exercises.</p> <p>From the landing page, click on the 'Collections' link, then click on the 'Surface weather observations from Malawi' link.</p> <p></p> <p>Click on the 'Queryables' link.</p> <p></p> <p>Question</p> <p>Which queryable would be used to filter by station identifier?</p> <p>Navigate to the previous page (i.e. <code>http://localhost/oapi/collections/urn:x-wmo:md:mwi:mwi_met_centre:surface-weather-observations</code>)</p> <p>Click on the 'Browse' link.</p> <p>Question</p> <p>How can we visualize the JSON response?</p> <p>Inspect the JSON response of the observations.</p> <p>Question</p> <p>How many records are returned?</p> <p>Question</p> <p>How can we limit the response to 3 observations?</p> <p>Question</p> <p>How can we sort the response by the latest observations?</p> <p>Question</p> <p>How can we filter the observations by a single station?</p> <p>Question</p> <p>How can we receive the observations as a CSV?</p> <p>Question</p> <p>How can we show a single observation (id)?</p>"},{"location":"practical-sessions/data-api-usage-and-queries/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>use the wis2box API to query and filter your stations</li> <li>use the wis2box API to query and filter your data</li> </ul>"},{"location":"practical-sessions/data-ingest-and-monitoring/","title":"Data ingest and monitoring","text":""},{"location":"practical-sessions/data-ingest-and-monitoring/#introduction","title":"Introduction","text":"<p>In this session you will learn various ways to ingest data into your wis2box and learn how you can monitor if your data is being ingested without errors.</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#preparation","title":"Preparation","text":"<p>Login to you student VM using your SSH client.</p> <p>Make sure wis2box is up and running:</p> <pre><code>cd ~/wis2box-1.0b4\npython3 wis2box-ctl.py start\npython3 wis2box-ctl.py status\n</code></pre> <p>Make sure your have MQTT Explorer running and connected to your instance.</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#open-the-grafana-dashboard","title":"Open the Grafana dashboard","text":"<p>Open the Grafana dashboard home-page at <code>http://&lt;your-host&gt;:3000</code></p> <p></p> <p>Question</p> <p>Are there any errors reported so far?</p> <p>Have there been any WIS2 notifications published in the last 24 hours?</p> <p>Keep a web browser tab open with the Grafana dashboard during the next few exercises to monitor the status of your data publishing.</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#ingesting-your-data-into-wis2box","title":"Ingesting your data into wis2box","text":"<p>You can use multiple methods to ingest data into wis2box and start publishing notifications to WIS2. </p> <p>Previously you used the <code>wis2box data ingest</code> command from within the wis2box-management container, which requires the data to be available on the wis2box instance.</p> <p>Another method for manually ingesting data is to use the <code>MinIO</code> admin interface to upload a file into the <code>wis2box-incoming</code> bucket. </p> <p>If your data-collection software supports sending data to an FTP endpoint you could use the optional wis2box-ftp container setup.</p> <p>You can also automate data ingest using a script to copy data into the <code>wis2box-incoming</code> bucket at regular intervals, for example using Python and the MinIO-client.</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#download-test-data","title":"Download test data","text":"<p>Click on the two links below and download two new data samples on your computer:</p> <p>WIGOS_0-454-2-AWSBILIRA_new.csv</p> <p>WIGOS_0-454-2-AWSCHIKANGAWA_new.csv</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#minio-admin-interface","title":"MinIO admin interface","text":"<p>Open a new tab in your web browser and visit the page <code>http://&lt;your-host&gt;:9001</code>. You should see the login screen for MinIO.  You can login with username <code>minio</code> and password <code>minio123</code>:</p> <p></p> <p>You should be see the buckets 'wis2box-archive', 'wis2box-incoming', 'wis2box-public'.</p> <p>You can click 'browse' to view the contents of the buckets. </p> <p>Navigate to the wis2box-incoming bucket:</p> <p></p> <p>Click the Create new path button and create the new folder path: <code>/test/data/</code>.</p> <p></p> <p>And then upload the file <code>WIGOS_0-454-2-AWSBILIRA_new.csv</code> into the folder <code>wis2box-incoming/test/data</code>.</p> <p>View the Grafana dashboard</p> <p>Go back to the Grafana dashboard on your instance at port 3000.</p> <p>You should see the following error:</p> <p></p> <p>Navigate the directory structure until you are in the folder <code>wis2box-incoming/mwi/mwi_wmo_demo/data/core/weather/surface-based-observations/synop</code></p> <p>Upload the file <code>WIGOS_0-454-2-AWSBILIRA_new.csv</code> to <code>wis2box-incoming/mwi/mwi_wmo_demo/data/core/weather/surface-based-observations/synop</code></p> <p>View the Grafana dashboard</p> <p>Check the Grafana dashboard; can you confirm the wis2box workflow was initiated after you uploaded your data?</p> <p>View new messages on your wis2box-broker</p> <p>Check MQTT Explorer, can you confirm that new messages were successfully published on your wis2box broker?</p> <p>Note</p> <p>The wis2box interprets the folder-structure in the <code>wis2box-incoming</code> bucket as the corresponding topic-hierarchy for the file.</p> <p><code>mwi.mwi_wmo_demo.data.core.weather.surface-based-observations.synop</code></p> <p>corresponds to the path:</p> <p><code>mwi/mwi_wmo_demo/data/core/weather/surface-based-observations/synop</code></p> <p>If there are no data-mappings defined for the topic-hierarchy corresponding to the directory that received data, wis2box will not initiate the workflow.</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#wis2box-ftp","title":"wis2box FTP","text":"<p>To allow your data to be accessible over FTP you can use the wis2box-ftp container, which provides a service that forwards data received over FTP to MinIO.</p> <p>For the purpose of this training you can use your predefined configuration in <code>~/wis2box-1.0b4/ftp.env</code> to start your wis2box-ftp as follows:</p> <pre><code>cd ~/wis2box-1.0b4/\ndocker-compose -f docker-compose.wis2box-ftp.yml --env-file ftp.env up -d\n</code></pre> <p>To test the FTP service, you can use WinSCP on your local laptop and prepare the connection to the wis2box-ftp container as follows (password=<code>wis2box</code>)</p> <p></p> <p>Once you have established the connection you will land in an empty directory. </p> <p>Select the option to create a 'new directory':</p> <p></p> <p>Create the directory <code>mwi/mwi_wmo_demo/data/core/weather/surface-based-observations/synop</code></p> <p>Enter the new directory you created and you can copy the file <code>WIGOS_0-454-2-AWSCHIKANGAWA_new.csv</code> from your host machine on the wis2box-ftp:</p> <p></p> <p>Check your Grafana dashboard and MQTT Explorer to review the result of copying the file in the wis2box-ftp.</p> <p>Question</p> <p>Did you manage to successfully publish WIS2 notifications for your new data?</p> <p>If not, review the errors reported and try to determine what went wrong.</p> <p>Note</p> <p>You can run <code>docker logs wis2box-ftp</code> to check if the FTP service is running correctly.</p> <p>Note</p> <p>You can view ftp-configuration in <code>ftp.env</code> from the command line:</p> <pre><code>cat ~/wis2box-1.0b4/ftp.env\n</code></pre> <pre><code>FTP_USER=wis2box\nFTP_PASS=wis2box\nFTP_HOST=testuser.wis2.training\nWIS2BOX_STORAGE_ENDPOINT=http://testuser.wis2.training:9000\nWIS2BOX_STORAGE_USER=minio\nWIS2BOX_STORAGE_PASSWORD=minio123\nLOGGING_LEVEL=WARNING\n</code></pre> <p>To change the username/password for the wis2box FTP service, edit the file <code>ftp.env</code> and update <code>FTP_USER</code> and <code>FTP_PASS</code>.</p> <p>If you you update your storage credentials from the default <code>minio</code>/<code>minio123</code>, you will also need to update the values in <code>ftp.env</code>.</p> <p>See wis2box-ftp documentation for more information on how to use the wis2box-ftp service.</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#minio-python-client-optional-exercise","title":"MinIO Python client (optional exercise)","text":"<p>You may want to automate data ingest from your system into wis2box using Python tools.</p> <p>MinIO provides a Python client which can be installed as follows:</p> <pre><code>pip3 install minio\n</code></pre> <p>On your student VM the 'minio' module for Python will already be installed.</p> <p>Go to the directory <code>exercise-materials/data-ingest</code> and run the example script using the following command:</p> <pre><code>cd ~/exercise-materials/data-ingest\npython3 examples/scripts/copy_to_incoming.py\n</code></pre> <p>Note</p> <p>The sample script needs to be modified before it can be used. </p> <p>The script needs to know the correct endpoint for accessing MinIO on your wis2box. If wis2box is running on your host, the MinIO endpoint is available at <code>http://&lt;your-host&gt;:9000</code>.</p> <p>The sample script provides the basic structure for copying a file into MinIO. Try to ingest a data sample of your choosing using this script.</p> <p>ingest data using Python</p> <p>Use the Python example provided to create your own Python script to ingest data into your wis2box.  </p> <p>Ensure that you:</p> <ul> <li>define the correct MinIO endpoint for your host</li> <li>define the correct path in MinIO for the topics defined in your <code>data-mappings.yml</code></li> <li>determine the correct local path where the script can access the data to ingest</li> </ul> <p>Ensure that the script runs correctly and new data notifications are published on your wis2box broker. Review and correct any errors reported on the Grafana dashboard:</p>"},{"location":"practical-sessions/data-ingest-and-monitoring/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>trigger wis2box workflow using different data ingest methods</li> <li>monitor the status of your data ingest and publishing</li> </ul>"},{"location":"practical-sessions/downloading-and-finding-data-from-wis2/","title":"Downloading and finding data from WIS2","text":""},{"location":"practical-sessions/downloading-and-finding-data-from-wis2/#introduction","title":"Introduction","text":"<p>In this session you will learn how to discover data from the WIS2 Global Discovery Catalogue (GDC) and download data from a WIS2 Global Broker (GB).</p>"},{"location":"practical-sessions/downloading-and-finding-data-from-wis2/#preparation","title":"Preparation","text":"<p>Note</p> <p>Before starting please login to your student VM.</p>"},{"location":"practical-sessions/downloading-and-finding-data-from-wis2/#downloading-data-with-pywis-pubsub","title":"Downloading data with pywis-pubsub","text":"<p>The first practical session used MQTT Explorer to connect to the M\u00e9t\u00e9o-France Global Broker.</p> <p>Let's use the pywis-pubsub to subscribe using a command line tool.</p> <pre><code>pywis-pubsub subscribe --help\n</code></pre> <p>Update the sample configuration (see the sections marked TBD) to connect to the M\u00e9t\u00e9o-France Global Broker:</p> <pre><code>vi ~/exercise-materials/pywis-pubsub-exercises/config.yml\n</code></pre> <p>Open MQTT Explorer and connect to the M\u00e9t\u00e9o-France Global Broker.</p> <p>Update the following values in the configuration:</p> <ul> <li>broker: <code>mqtts://everyone:everyone@globalbroker.meteo.fr:8883</code></li> <li>subscribe_topics: fill in one to many topics <code>origin/#</code> and <code>cache/#</code> (on separate lines)</li> <li>storage.option.path: add a directory to where data should be downloaded</li> </ul> <p>Run the <code>pywis-pubsub</code> command:</p> <pre><code>pywis-pubsub subscribe -c ~/exercise-materials/pywis-pubsub-exercises/config.yml --verbosity INFO -d\n</code></pre> <p>Note</p> <p>The above command will download data to your local system for demo purposes.  For operational environments you will need to consider and manage diskspace requirements as part of your workflow.</p> <p>Question</p> <p>What is the format of the data notifications that are displayed on the screen?</p> <p>Question</p> <p>Is there data being downloaded?  How can we run the <code>pywis-pubsub</code> command to be able to download the data (hint: review the options when running the <code>pywis-pubsub subscribe --help</code> command)?</p> <p>Stop the <code>pywis-pubsub</code> command (CTRL-C) and update the configuration to be able to download the data to <code>/tmp/wis2-data</code>.</p> <p>Try spatial filtering with a bounding box:</p> <pre><code>pywis-pubsub subscribe -c ~/exercise-materials/pywis-pubsub-exercises/config.yml --verbosity INFO -d -b -142,42,-52,84\n</code></pre> <p>Note</p> <p>Try using your own bounding box (format is <code>west,south,east,north</code>, in decimal degrees).</p>"},{"location":"practical-sessions/downloading-and-finding-data-from-wis2/#finding-data-with-pywiscat","title":"Finding data with pywiscat","text":"<p>Let's use pywiscat to query the GDC</p> <pre><code>pywiscat wis2 search\n</code></pre> <p>Question</p> <p>How many records are returned from the search?</p> <p>Let's try querying the GDC with a keyword:</p> <pre><code>pywiscat wis2 search -q radar\n</code></pre> <p>Question</p> <p>What is the data policy of the results?</p> <p>Try additional queries with <code>-q</code></p> <p>Tip</p> <p>The <code>-q</code> flag allows for the following syntax:</p> <ul> <li><code>-q sea</code>: find all records with the word \"sea\"</li> <li><code>-q \"NOT sea\"</code>: find all records that do not contain the word \"sea\"</li> <li><code>-q \"sea AND ice\"</code>: find all records with both \"sea\" and \"ice\"</li> <li><code>-q \"sea OR ice\"</code>: find all records with both \"sea\" and \"ice\"</li> <li><code>-q \"sea NOT ice\"</code>: find all records with \"sea\" but not \"ice\"</li> <li><code>-q \"sea~\"</code>: fuzzy search</li> </ul> <p>If searching for terms with spaces, enclose in double quotes.</p> <p>Let's get more details on a specific search result that we are interested in:</p> <pre><code>pywiscat wis2 get &lt;id&gt;\n</code></pre> <p>Tip</p> <p>Use the <code>id</code> value from the previous search.</p>"},{"location":"practical-sessions/downloading-and-finding-data-from-wis2/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>use pywis-pubsub to subscribe to a Global Broker and download data to your local system</li> <li>use pywiscat to discover datasets from the Global Discovery Catalogue</li> </ul>"},{"location":"practical-sessions/environment-variables/","title":"wis2box environment variables","text":""},{"location":"practical-sessions/environment-variables/#introduction","title":"Introduction","text":"<p>In this session you will customize your wis2box environment variables and re-initialize your wis2box.</p>"},{"location":"practical-sessions/environment-variables/#preparation","title":"Preparation","text":"<p>Login to your student VM using WinSCP (using SCP-protocol) and PuTTY.</p>"},{"location":"practical-sessions/environment-variables/#re-initialize-wis2box","title":"re-initialize wis2box","text":"<p>Stop your wis2box:</p> <pre><code>cd ~/wis2box-1.0b4/\npython3 wis2box-ctl.py stop\n</code></pre> <p>Stop the wis2box-ftp service: <pre><code>docker-compose -f docker-compose.wis2box-ftp.yml down\n</code></pre></p> <p>Check that there are no longer any Docker-containers running on your system: <pre><code>docker ps -a\n</code></pre></p> <p>Check that you still have Docker volumes remaining on your system: <pre><code>docker volume ls\n</code></pre></p> <p>To delete all Docker volumes that are not associated to a Docker Container, run the following command: <pre><code>docker volume prune\n</code></pre></p> <p>Check that your docker volumes are removed:</p> <pre><code>docker volume ls\n</code></pre> <p>wis2box and Docker volumes</p> <p>Note that deleting the Docker volumes is a quick way to re-initialize wis2box.</p> <p>It will also delete all information stored in the ElasticSearch API backend (i.e. discovery metadata, station metadata, data notifications, and previously ingested observation data).</p> <p>Do NOT delete the <code>es-data</code>-volume if you want preserve previously ingested observation data.</p>"},{"location":"practical-sessions/environment-variables/#configure-your-own-devenv","title":"Configure your own <code>dev.env</code>","text":"<p>The wis2box setup reads environment variables from <code>dev.env</code>. </p> <p>Make sure you are in the wis2box-directory and the check the current content of your <code>dev.env</code>.</p> <pre><code>cd ~/wis2box-1.0b4/\ncat dev.env\n</code></pre> <p>This is the minimum setup that enabled you to run your wis2box in the previous exercises. </p> <p>This setup was using the pre-defined configuration stored in <code>~/exercise-materials/wis2box-test-data</code> as defined <code>WIS2BOX_HOST_DATADIR</code>.</p> <p>WIS2BOX_URL and WIS2BOX_API_URL</p> <p>Note the current values of \"WIS2BOX_URL\" and \"WIS2BOX_API_URL\" are referring to your student-VM. </p> <p>Make sure you keep these values when editing your <code>dev.env</code></p> <p>In the next few steps we will review how to update some of key environment variables used in wis2box by editing <code>dev.env</code> in the directory <code>wis2box-1.0b4</code>.</p> <p>You can use WinSCP to connect to your instance and edit this file or you can edit the file from the command line using PuTTY.</p>"},{"location":"practical-sessions/environment-variables/#define-your-own-wis2box-data-directory","title":"Define your own wis2box data directory","text":"<p>Using the SSH client connected to your student VM, use the following command to create a new directory on your instance: <pre><code>mkdir -p ~/wis2box-data\n</code></pre></p> <p>Inside this directory create the following directory structure for your discovery metadata and station metadata:</p> <pre><code>mkdir -p ~/wis2box-data/metadata/discovery\nmkdir -p ~/wis2box-data/metadata/station\n</code></pre>"},{"location":"practical-sessions/environment-variables/#create-an-empty-data-mappingsyml","title":"create an (empty) <code>data-mappings.yml</code>","text":"<p>The wis2box requires the file <code>data-mappings.yml</code> stored in your wis2box data directory. </p> <p>Use the following commands to create an (empty) <code>data-mappings.yml</code> that you will populate at a later step.  <pre><code>echo \"data:\" &gt; ~/wis2box-data/data-mappings.yml\n</code></pre></p>"},{"location":"practical-sessions/environment-variables/#create-an-empty-station-listcsv","title":"create an (empty) <code>station-list.csv</code>","text":"<p>The wis2box requires the file <code>metadata/station/station_list.csv</code> store in your wis2box data directory.</p> <p>Use the following commands to create <code>metadata/station/station_list.csv</code> (headers only):</p> <pre><code>echo \"station_name,wigos_station_identifier,traditional_station_identifier,facility_type,latitude,longitude,elevation,territory_name,wmo_region\" &gt; ~/wis2box-data/metadata/station/station_list.csv\n</code></pre> <p>Edit <code>dev.env</code> (using WinSCP or from the command line):</p> <p>Comment out the original <code>WIS2BOX_HOST_DATADIR</code> :</p> <p><code># WIS2BOX_HOST_DATADIR=/home/&lt;your-username&gt;/exercise-materials/wis2box-test-data</code> </p> <p>And add the following to point to your new directory:</p> <p><code>WIS2BOX_HOST_DATADIR=/home/&lt;your-username&gt;/wis2box-data</code></p>"},{"location":"practical-sessions/environment-variables/#define-custom-credentials-for-your-broker-and-storage","title":"define custom credentials for your broker and storage","text":"<p>Edit the file <code>dev.env</code> and add the following to customize the default broker credentials (replace <code>XXXXXXXX</code> with your own password):</p> <pre><code># broker credentials\nWIS2BOX_BROKER_USERNAME=wis2box\nWIS2BOX_BROKER_PASSWORD=XXXXXXXX\n</code></pre> <p>And the following content to <code>dev.env</code> to set the storage credentials (replace XXXXXXXX with your own password)</p> <pre><code># storage credentials\nWIS2BOX_STORAGE_USERNAME=minio\nWIS2BOX_STORAGE_PASSWORD=XXXXXXXX\n</code></pre> <p>storage credentials requirements</p> <p>Username should be 3 or more characters</p> <p>Password should be 8 or more characters</p> <p>Finally, add the following block to your <code>dev.env</code> to ensure the credentials are propagated across all services:</p> <pre><code># wis2box-public-broker\nWIS2BOX_BROKER_PUBLIC=mqtt://${WIS2BOX_BROKER_USERNAME}:${WIS2BOX_BROKER_PASSWORD}@mosquitto:1883\n# minio-setup\nMINIO_ROOT_USER=${WIS2BOX_STORAGE_USERNAME}\nMINIO_ROOT_PASSWORD=${WIS2BOX_STORAGE_PASSWORD}\nMINIO_NOTIFY_MQTT_USERNAME_WIS2BOX=${WIS2BOX_BROKER_USERNAME}\nMINIO_NOTIFY_MQTT_PASSWORD_WIS2BOX=${WIS2BOX_BROKER_PASSWORD}\n</code></pre> <p>The content of you <code>dev.env</code> should now look as follows (except for your own passwords and URLs):</p> <p></p>"},{"location":"practical-sessions/environment-variables/#restart-wis2box","title":"Restart wis2box","text":"<p>Start the wis2box and check the status: <pre><code>python3 wis2box-ctl.py start\npython3 wis2box-ctl.py status\n</code></pre></p>"},{"location":"practical-sessions/environment-variables/#check-datawis2box-in-wis2box-management","title":"Check /data/wis2box in wis2box-management","text":"<p>Login to the wis2box-management container using the following command:</p> <pre><code>python3 wis2box-ctl.py login\n</code></pre> <p>Run the following command to view the environment variable <code>WIS2BOX_HOST_DATADIR</code>:</p> <pre><code>echo $WIS2BOX_HOST_DATADIR\n</code></pre> <p>returns:</p> <pre><code>/home/&lt;your-username&gt;/wis2box-data/\n</code></pre> <p>And check the content of <code>/data/wis2box</code> inside the wis2box-management container:</p> <pre><code>ls /data/wis2box/\n</code></pre> <p>returns:</p> <pre><code>data-mappings.yml metadata\n</code></pre> <p>Note</p> <p>The directory defined by <code>$WIS2BOX_HOST_DATADIR</code> gets mounted as <code>/data/wis2box</code> inside the wis2box-management container.</p>"},{"location":"practical-sessions/environment-variables/#re-connect-to-mqtt-explorer","title":"Re-connect to MQTT-explorer","text":"<p>Try to reconnect to MQTT Explorer using the values you defined for <code>WIS2BOX_BROKER_USERNAME</code> and <code>WIS2BOX_BROKER_PASSWORD</code></p>"},{"location":"practical-sessions/environment-variables/#access-the-minio-user-interface","title":"Access the MinIO user interface","text":"<p>Access the MinIO UI at <code>http://&lt;your-host-name&gt;:9001</code> using the values you defined for <code>WIS2BOX_STORAGE_USERNAME</code> and <code>WIS2BOX_STORAGE_PASSWORD</code></p>"},{"location":"practical-sessions/environment-variables/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>reinitialize wis2box services</li> <li>set the wis2box data directory</li> <li>set custom passwords for your broker and storage</li> </ul>"},{"location":"practical-sessions/wis2box-introduction/","title":"wis2box introduction","text":""},{"location":"practical-sessions/wis2box-introduction/#introduction","title":"Introduction","text":"<p>In this session you will run the wis2box software that was pre-installed on your student VM using the test data configuration.</p> <p>You will review and access the services provided by your wis2box: the MQTT broker and HTTP accessible services and view how the services work when manually ingesting some test-data.</p> <p>wis2box installation and configuration</p> <p>The latest wis2box release has been pre-installed on your student VM using the release archive available on GitHub:</p> <pre><code>wget https://github.com/wmo-im/wis2box/releases/download/1.0b4/wis2box-setup-1.0b4.zip\nunzip wis2box-setup-1.0b4.zip\n</code></pre> <p>You can always find the latest 'wis2box-setup' archive at https://github.com/wmo-im/wis2box/releases.</p> <p>Your student VM has been pre-configured with a dataset for Malawi and includes some previously ingested data. Later during this training you will learn how to setup datasets of your own.</p> <p>All the required steps for installation and configuration of the wis2box can be found in the wis2box-documentation</p>"},{"location":"practical-sessions/wis2box-introduction/#preparation","title":"Preparation","text":"<p>Login to your designated VM with your username and password.</p>"},{"location":"practical-sessions/wis2box-introduction/#wis2box-start-and-status","title":"wis2box start and status","text":"<p>Navigate to the directory containing the wis2box software stack:</p> <pre><code>cd ~/wis2box-1.0b4\n</code></pre> <p>Start wis2box with the following command:</p> <pre><code>python3 wis2box-ctl.py start\n</code></pre> <p>Inspect the status with the following command:</p> <pre><code>python3 wis2box-ctl.py status\n</code></pre> <p>Repeat this command until all services are up and running.</p> <p>Question</p> <p>What services are running? Which ports are used for each service?</p> <p>wis2box and Docker</p> <p>wis2box runs as a set of Docker containers managed by docker-compose.</p> <p>The services are defined in the various <code>docker-compose*.yml</code> which can be found in the <code>~/wis2box-1.0b4/</code> directory.</p> <p>The Python script <code>wis2box-ctl.py</code> is used to run the underlying Docker Compose commands that control the wis2box services.</p>"},{"location":"practical-sessions/wis2box-introduction/#wis2box-ui","title":"wis2box UI","text":"<p>Open a web browser and visit the page <code>http://&lt;your-host&gt;</code>.</p> <p>This is the default wis2box web application (running via the wis2box-ui container). </p> <p>Click the \"EXPLORE\" option on <code>http://&lt;your-host&gt;</code>.</p> <p>View latest data per station on the wis2box UI</p> <p>Click on on a station in the station list or hover your mouse over a station in the map to see the latest data for that station.</p> <p></p> <p>View data profile over time per measured variable</p> <p>After selecting a station in the map, click on \"data\" and select a variable to see a graph of the measured variable over time.</p> <p></p> <p>Question</p> <p>What is last timestamp in UTC for which the Malawi station \"Bilira\" received data?</p>"},{"location":"practical-sessions/wis2box-introduction/#wis2box-api","title":"wis2box API","text":"<p>Open a new tab and navigate to the page <code>http://&lt;your-host&gt;/oapi</code>.</p> <p></p> <p>This is the wis2box API (running via the wis2box-api container).</p> <p>To view collections currently published to the API, click <code>View the collections in this service</code>.</p> <p>Question</p> <p>What collections are currently available?</p> <p>Question</p> <p>How many data notifications have been published?</p> <p>Question</p> <p>How many stations are configured?</p>"},{"location":"practical-sessions/wis2box-introduction/#wis2box-broker","title":"wis2box-broker","text":"<p>Open the MQTT Explorer on your computer and prepare a new connection to connect to your broker (running via the wis2box-broker container).</p> <p>Use the following connection details:</p> <ul> <li>Protocol: mqtt://</li> <li>Host: <code>&lt;your-host&gt;</code></li> <li>Port: 1883</li> <li>Username: wis2box</li> <li>Password: wis2box</li> <li>under 'ADVANCED', subscribe to the topics <code>$SYS/#</code> and <code>origin/#</code></li> </ul> <p>Make sure to click \"SAVE\" to store your connection details.</p> <p></p> <p>Once you are connected, you should see statistics being published by your broker on the <code>$SYS</code> topic.</p> <p>Make sure MQTT Explorer is connected to your broker before proceeding to the next exercise: </p>"},{"location":"practical-sessions/wis2box-introduction/#publishing-wis2-data","title":"Publishing WIS2 data","text":"<p>To demonstrate how wis2box can publish WIS2 data we will manually ingest some data from the command line:</p> <p>In your SSH client window, ensure you are in the <code>~/wis2box-1.0b4</code> directory and login to the wis2box-management container as follows:</p> <pre><code>cd ~/wis2box-1.0b4/\npython3 wis2box-ctl.py login\n</code></pre> <p>Note</p> <p>This command is equivalent to <code>docker exec -it wis2box-management /bin/bash</code>, meaning that you have entered an interactive shell inside the wis2box-management container.</p> <p>Run the following command to ingest some additional data: <pre><code>wis2box data ingest -th mwi.mwi_wmo_demo.data.core.weather.surface-based-observations.synop -p /data/wis2box/observations/malawi-new-core/\n</code></pre></p> <p>After the data ingest runs successfully, you should be able to view new messages that have been published on your wis2box broker in MQTT Explorer.</p> <p>Question</p> <p>What is the topic used to publish notifications for new data? How many WIS2 data notifications have been published?</p> <p>download data</p> <p>What is the URL that allows you to download the published data in BUFR-format? Copy and paste the URL in your browser to verify you can download the corresponding <code>.bufr4</code> file.</p> <p>Go back to your browser and visit the wis2box UI.</p> <p>review new data</p> <p>Did your new data appear in wis2box? Find the stations for which you ingested new data and verify new data is available.</p>"},{"location":"practical-sessions/wis2box-introduction/#publishing-wis2-data-with-access-control","title":"Publishing WIS2 data with access control","text":"<p>We will now publish some more data on the topic containing <code>data.recommended</code></p> <p>In your SSH client window, login to the wis2box-management container:</p> <pre><code>cd ~/wis2box-1.0b4/\npython3 wis2box-ctl.py login\n</code></pre> <p>Run the following command to ingest some additional data: <pre><code>wis2box data ingest -th mwi.mwi_wmo_demo.data.recommended.weather.surface-based-observations.synop -p /data/wis2box/observations/malawi-new-reco/\n</code></pre></p> <p>Question</p> <p>What is the topic used to publish notifications for the new data? How many WIS2 data notifications have been published?</p> <p>download data</p> <p>What is the URL that allows you to download the newly published data in BUFR-format? Copy and paste the URL in your browser to verify you can download the corresponding <code>.bufr4</code> file.</p> <p>Downloading restricted data</p> <p>You will not be able to download the data using the URL in the message published on <code>origin/a/wis2/mwi/mwi_wmo_demo/data/recommended/</code> as the data access has been restricted by the data publisher. In this case you will get the error <code>401 Authorization Required</code>.</p> <p>The data is currently restricted with the access token <code>mysecrettoken</code>. In order to download the data you would need to add this token to the header:</p> <pre><code>wget --header \"Authorization: Bearer mysecrettoken\" http://testuser.wis2.training/data/2023-06-07/wis/mwi/mwi_wmo_demo/data/recommended/weather/surface-based-observations/synop/WIGOS_0-454-2-AWSCHIKWAWA_20230607T085500.bufr4\n</code></pre>"},{"location":"practical-sessions/wis2box-introduction/#conclusion","title":"Conclusion","text":"<p>Congratulations!</p> <p>In this practical session, you learned how to:</p> <ul> <li>start wis2box and check the status of its components</li> <li>ingest some data test observations</li> <li>access the wis2box UI, API, MinIO UI and Grafana dashboard</li> <li>use access control for restricted datasets</li> </ul>"},{"location":"schedule/indonesia-2023-10/","title":"9 - 13 October 2023: Jakarta, Indonesia","text":"<p>TODO</p>"},{"location":"schedule/namibia-2023-03/","title":"20 - 24 March 2023: Windhoek, Namibia \ud83c\uddf3\ud83c\udde6","text":""},{"location":"schedule/namibia-2023-03/#venue","title":"Venue","text":"<p>Hotel Safari, Managed By Accor</p> <p>Corner Of Auas Aviation Road, 9000 Windhoek, Namibia</p>"},{"location":"schedule/namibia-2023-03/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>to be able to explain WIS2 architecture</li> <li>to be able to install and configure the WIS2 in a box software</li> <li>to be able to operate a WIS2 Node</li> </ul>"},{"location":"schedule/namibia-2023-03/#timetable","title":"Timetable","text":""},{"location":"schedule/namibia-2023-03/#day-1","title":"Day 1","text":"Time Subject Instructor(s) Presentation(s) 8h30 - 9h Registration 09h - 11h Opening photo and Round table 11h - 11h30 Break 11h30 - 12h WIS2 Implementation Plan Hassan Haddouch Presentation 12h - 12h30 WIS2 Architecture Enrico Fucile Presentation 12h30 - 13h30 Lunch break 13h30 - 14h30 Practical session: Connecting to WIS2 over MQTT Maaike Limper/Timo Proescholdt 14h30 - 15h15 Introducing WIS2 in a box Tom Kralidis Presentation 15h15 - 15h45 Break 15h45 - 16h30 WIS2 in a box case studies Enrico Fucile Presentation 16h30 - 17h Wrap-up  / open issues Timo Proescholdt"},{"location":"schedule/namibia-2023-03/#day-2","title":"Day 2","text":"Time Subject Instructor(s) Presentation(s) 9h - 9h30 The training environment Timo Proescholdt Presentation 9h30 - 11h Practical session: Accessing your student VM Maaike Limper/Timo Proescholdt 11h - 11h30 Break 11h30 - 12h30 WIS2 in a box architecture, project and installation Tom Kralidis ArchitectureProject and installation 12h30 - 13h30 Lunch break 13h30 - 15h Practical session: Installing WIS2 box with test data Tom Kralidis/Maaike Limper 15h - 15h30 Break 15h30 - 16h30 Practical session: Installing WIS2 box with test data Tom Kralidis/Maaike Limper 16h30 - 17h Group discussion: insights and challenges installing wis2box Timo Proescholdt"},{"location":"schedule/namibia-2023-03/#day-3","title":"Day 3","text":"Time Subject Instructor(s) Presentation(s) 9h - 10h BUFR and ecCodes Enrico Fucile BUFR in a nutshellBUFR with ecCodes 10h - 11h Conversion to BUFR: synop2bufr Enrico Fucile/Maaike Limper SYNOP to BUFR 11h - 11h30 Break 11h30 - 12h30 Conversion to BUFR: csv2bufr Enrico Fucile/Maaike Limper CSV to BUFR 12h30 - 13h30 Lunch break 13h30 - 14h DAYCLI Enrico Fucile Daily Climate data (DAYCLI) 14h - 14h30 Practical session: Converting DAYCLI data to BUFR Enrico Fucile 14h30 - 15h Break 15h - 16h30 Convert your data Enrico Fucile/Maaike Limper 16h30 - 17h Group discussion: insights and challenges converting data to BUFR Timo Proescholdt"},{"location":"schedule/namibia-2023-03/#day-4","title":"Day 4","text":"Time Subject Instructor(s) Presentation(s) 9h - 11h Installing wis2box with test dataConfiguring data mappingsConfiguring WIS2 discovery metadataConfiguring station metadata Tom Kralidis/Maaike Limper 11h - 11h30 Break 11h30 - 12h30 wis2box practical session: runtime configuration setup (continued) Tom Kralidis/Maaike Limper 12h30 - 13h30 Lunch break 13h30 - 15h30 Practical session: Data ingest and monitoring Tom Kralidis/Maaike Limper 15h30 - 17h Practical session: Downloading and finding data from WIS2 Tom Kralidis/Maaike Limper WIS2 data access"},{"location":"schedule/namibia-2023-03/#day-5","title":"Day 5","text":"Time Subject Instructor(s) Presentation(s) 9h - 10h30 Joining WIS2 as a WIS2 Node Timo Proescholdt Participating in the pilot phase as a WIS2 Node 10h30 - 11h Next steps with WIS2 Hassan Haddouch/Enrico Fucile Next steps with WIS2 11h - 11h30 Round table: participants' plans for WIS2 all WIS2 National Plan 11h30 - 12h Closing ceremony all"},{"location":"schedule/namibia-2023-03/#participants","title":"Participants","text":"Country Name 1 Algeria \ud83c\udde9\ud83c\uddff Abderraouf KADEM 2 Congo \ud83c\udde8\ud83c\uddec Francilly Lardin SAMBA 3 Eswatini \ud83c\uddf8\ud83c\uddff Mbongeni Ian GAMEDZE 4 Kenya \ud83c\uddf0\ud83c\uddea Peter Kipkorir MUTAI 5 Malawi \ud83c\uddf2\ud83c\uddfc Patrick Edward MTINGWI 6 Morocco \ud83c\uddf2\ud83c\udde6 Chems Eddine EL GARRAI 7 Namibia \ud83c\uddf3\ud83c\udde6 Odillo KGOBETSI 8 Namibia \ud83c\uddf3\ud83c\udde6 Laina AMUNJELA (Ms.) 9 Namibia \ud83c\uddf3\ud83c\udde6 Seblonica IMALWA (Ms.) 10 Namibia \ud83c\uddf3\ud83c\udde6 Prince Julian HAOSEB 11 Namibia \ud83c\uddf3\ud83c\udde6 Uvatera TJIMUNE 12 Namibia \ud83c\uddf3\ud83c\udde6 Vilho NDEUNYEMA 13 South Africa \ud83c\uddff\ud83c\udde6 Tshepo Hope TAWANE 14 South Africa \ud83c\uddff\ud83c\udde6 Teko Mohono 15 South Africa \ud83c\uddff\ud83c\udde6 Thula Ngidi 16 South Africa \ud83c\uddff\ud83c\udde6 Christa Ferreira (Ms.) 17 Tanzania     \ud83c\uddf9\ud83c\uddff Rose Dudley SENYAGWA (Ms.) 18 Zambia      \ud83c\uddff\ud83c\uddf2 Naomi MUCHIPU (Ms.) 19 Zimbabwe \ud83c\uddff\ud83c\uddfc Joyce BANDA (Ms.) 20 Zimbabwe \ud83c\uddff\ud83c\uddfc Wilfred Janda CHAWAGUTA 21 Zimbabwe \ud83c\uddff\ud83c\uddfc Zvidzai Malvin KANENGONI"},{"location":"schedule/namibia-2023-03/#instructors","title":"Instructors","text":"Name Organization Enrico Fucile WMO Secretariat \ud83c\uddfa\ud83c\uddf3 Hassan Haddouch WMO Secretariat \ud83c\uddfa\ud83c\uddf3 Tom Kralidis Meteorological Service of Canada \ud83c\udde8\ud83c\udde6 Maaike Limper WMO Secretariat \ud83c\uddfa\ud83c\uddf3 Timo Proescholdt WMO Secretariat \ud83c\uddfa\ud83c\uddf3"},{"location":"schedule/trinidad-and-tobago-2023-06/","title":"12 - 16 June 2023: Port of Spain, Trinidad and Tobago \ud83c\uddf9\ud83c\uddf9","text":"<p>TODO</p>"}]}